{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is an implementation of PPO-clip for path selection for symbolic execution.\n",
    "Each epoch we communicate with jar-file for data gathering and wandb for logging."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "t6GWfxrs9gFR",
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Imports, meta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "BAP5ws3ofyyY",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: CUDA_DEVICE_ORDER=PCI_BUS_ID\n",
      "env: CUDA_VISIBLE_DEVICES=4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mandrey_podivilov\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# %%capture\n",
    "\n",
    "%env CUDA_DEVICE_ORDER=PCI_BUS_ID\n",
    "%env CUDA_VISIBLE_DEVICES=4\n",
    "\n",
    "from IPython.display import Javascript\n",
    "def resize_colab_cell():\n",
    "  display(Javascript('google.colab.output.setIframeHeight(0, true, {maxHeight: 600})'))\n",
    "get_ipython().events.register('pre_run_cell', resize_colab_cell)\n",
    "\n",
    "import warnings\n",
    "import numpy as np\n",
    "from numpy import random\n",
    "import copy\n",
    "import inspect\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.onnx\n",
    "import json\n",
    "from tqdm import tqdm, trange\n",
    "from time import time\n",
    "import os\n",
    "import math\n",
    "from operator import itemgetter\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.loader import DataLoader as GraphDataLoader\n",
    "from torch_geometric.data import Data as GraphData\n",
    "from torch_geometric.nn import GCNConv\n",
    "\n",
    "\n",
    "# !pip install wandb\n",
    "import wandb\n",
    "\n",
    "# !pip install onnx==1.12\n",
    "# import onnx\n",
    "\n",
    "wandb.login()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VJbCP9HE9gFV",
    "tags": []
   },
   "source": [
    "### Args (potentially immutable), login"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 17
    },
    "id": "z90K8IBjpUBu",
    "outputId": "cda45a33-90d7-4e4f-90aa-b43648ac4507",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "google.colab.output.setIframeHeight(0, true, {maxHeight: 600})"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'cuda'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size = 512\n",
    "max_nactions = 64\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "td_gamma=0.998\n",
    "json_path = '../Data/current_dataset.json'\n",
    "use_fork_discount = False\n",
    "batch_accumulation_steps = 1\n",
    "cuda_sync = False\n",
    "use_gnn = False\n",
    "gnn_in_nfeatures = 7\n",
    "gnn_out_nfeatures = 16\n",
    "features_dim = 36 + (gnn_out_nfeatures if use_gnn else 0)\n",
    "\n",
    "maybe_sync = torch.cuda.synchronize if cuda_sync else (lambda *args: None)\n",
    "jar_command = '/home/st-andrey-podivilov/java16/usr/lib/jvm/bellsoft-java16-amd64/bin/java -Dorg.jooq.no-logo=true -jar ../Game_env/usvm-jvm/build/libs/usvm-jvm-new.jar ../Game_env/jar_config.txt > ../Game_env/jar_log.txt'\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ndNrbEp79gFX",
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Models, modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 17
    },
    "id": "abh-k_ytgHWT",
    "outputId": "d7afca61-ea0b-4f4d-d851-95c77b7b2cc1",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "google.colab.output.setIframeHeight(0, true, {maxHeight: 600})"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "class FFM_layer(torch.nn.Module):\n",
    "    \"\"\"\n",
    "    wtf\n",
    "    \"\"\"\n",
    "    def __init__(self, input_dim):\n",
    "      super().__init__()\n",
    "      assert input_dim%2 == 0, 'even input_dim is more convenient'\n",
    "      self.fourier_matrix = torch.nn.Linear(input_dim, int(input_dim), bias=False)\n",
    "      nn.init.normal_(\n",
    "          self.fourier_matrix.weight,\n",
    "          std=1/np.sqrt(input_dim),\n",
    "      )\n",
    "      self.fourier_matrix.weight.requires_grad_(False)\n",
    "\n",
    "    def forward(self, x):\n",
    "      pre = x # self.fourier_matrix(x)\n",
    "      s = torch.sin(pre)\n",
    "      c = torch.cos(pre)\n",
    "      return torch.cat([x,s,c], dim=-1)\n",
    "    \n",
    "  \n",
    "class Attn_model(torch.nn.Module):\n",
    "  def __init__(\n",
    "    self,\n",
    "    d_model=512,\n",
    "    n_heads=8,\n",
    "    dim_feedforward=512, \n",
    "    dropout=0.0,    \n",
    "    use_FFM=True,\n",
    "  ):\n",
    "    super(Attn_model, self).__init__()\n",
    "    self.emb = nn.Sequential(\n",
    "      nn.LazyLinear(512),\n",
    "      nn.ReLU(),\n",
    "      nn.LayerNorm(512),\n",
    "      FFM_layer(512) if use_FFM else nn.Identity(),\n",
    "      nn.LazyLinear(d_model),\n",
    "      nn.ReLU(),\n",
    "    )\n",
    "    self.attn_EncoderLayer0 = nn.TransformerEncoderLayer(d_model, n_heads, dim_feedforward, dropout, batch_first=True)\n",
    "    self.head = nn.Sequential(\n",
    "      nn.LazyLinear(1),\n",
    "    )\n",
    "    self.sfmax = nn.Softmax(dim=-1)\n",
    "    \n",
    "  def forward(self, x, mask=None):\n",
    "    x = self.emb(x)\n",
    "    x = self.attn_EncoderLayer0(x, src_key_padding_mask=mask)\n",
    "    x = self.head(x).squeeze(-1)\n",
    "    if mask is None:\n",
    "      return self.sfmax(x)\n",
    "    inf_mask = mask.float().masked_fill(mask==True, -float('inf'))    \n",
    "    x = self.sfmax(x + inf_mask)\n",
    "    return x\n",
    "  \n",
    "  \n",
    "class Double_attn_model(torch.nn.Module):\n",
    "  def __init__(\n",
    "    self,\n",
    "    d_model=512,\n",
    "    n_heads=8,\n",
    "    dim_feedforward=512, \n",
    "    dropout=0.0,    \n",
    "    use_FFM=True,\n",
    "  ):\n",
    "    super(Double_attn_model, self).__init__()\n",
    "    self.emb = nn.Sequential(\n",
    "      nn.LazyLinear(512),\n",
    "      nn.ReLU(),\n",
    "      nn.LayerNorm(512),\n",
    "      FFM_layer(512) if use_FFM else nn.Identity(),\n",
    "      nn.LazyLinear(d_model),\n",
    "      nn.ReLU(),\n",
    "    )\n",
    "    self.attn_EncoderLayer0 = nn.TransformerEncoderLayer(d_model, n_heads, dim_feedforward, dropout, batch_first=True)\n",
    "    self.attn_EncoderLayer1 = nn.TransformerEncoderLayer(d_model, n_heads, dim_feedforward, dropout, batch_first=True)\n",
    "    self.head = nn.Sequential(\n",
    "      nn.LazyLinear(1),\n",
    "    )\n",
    "    self.sfmax = nn.Softmax(dim=-1)\n",
    "    \n",
    "  def forward(self, x, mask=None):\n",
    "    x = self.emb(x)\n",
    "    x = self.attn_EncoderLayer0(x, src_key_padding_mask=mask)\n",
    "    x = self.attn_EncoderLayer1(x, src_key_padding_mask=mask)\n",
    "    x = self.head(x).squeeze(-1)\n",
    "    if mask is None:\n",
    "      return self.sfmax(x)\n",
    "    inf_mask = mask.float().masked_fill(mask==True, -float('inf'))    \n",
    "    x = self.sfmax(x + inf_mask)\n",
    "    return x\n",
    "\n",
    "  \n",
    "class V_cell(torch.nn.Module):\n",
    "  \"\"\"\n",
    "  Predicts Returns by traversing trajectories.\n",
    "  We use its inner representations to enrich world embedding.\n",
    "  \"\"\"\n",
    "  def __init__(\n",
    "    self,\n",
    "    hidden_size=64,\n",
    "    dropout=0.0,\n",
    "    bias=True, \n",
    "    batch_first=True,\n",
    "  ):\n",
    "    super(V_cell, self).__init__()\n",
    "    self.hidden_size = hidden_size\n",
    "    self.num_layers = 2\n",
    "    self.emb = nn.Sequential(\n",
    "      nn.LazyLinear(64),\n",
    "      nn.LayerNorm(64),\n",
    "    )\n",
    "    self.lstm_cell = nn.LSTMCell(input_size=64, hidden_size=hidden_size)\n",
    "    self.lstm_cell2 = nn.LSTMCell(input_size=hidden_size, hidden_size=hidden_size)\n",
    "    self.head = nn.Sequential(\n",
    "      nn.Dropout(p=dropout),\n",
    "      nn.LazyLinear(128),\n",
    "      nn.ReLU(),\n",
    "      nn.LazyLinear(1),\n",
    "    )\n",
    "    \n",
    "  def forward(self, input_batch, prev_state_batch):\n",
    "    \"\"\"\n",
    "    input_batch: [batch_size, feature_size]\n",
    "    prev_state_batch: [2*num_layers, batch_size, hidden_size]\n",
    "    Outputs: [batch_size, 1], [2*num_layers, batch_size, hidden_size]\n",
    "    \"\"\"\n",
    "    h_p = prev_state_batch[[np.arange(self.num_layers) * 2]]\n",
    "    c_p = prev_state_batch[[np.arange(self.num_layers) * 2 + 1]]\n",
    "    x = self.emb(input_batch)\n",
    "    h1, c1 = self.lstm_cell(x, (h_p[0], c_p[0]))\n",
    "    h2, c2 = self.lstm_cell2(h1, (h_p[1], c_p[1]))\n",
    "    v = self.head(h2)\n",
    "    return v, torch.stack((h1, c1, h2, c2), dim=0)\n",
    "  \n",
    "\n",
    "class Q_Net(torch.nn.Module):\n",
    "  \"\"\"\n",
    "  Builds Q-network based on critic\n",
    "  \"\"\"\n",
    "  def __init__(\n",
    "    self,\n",
    "    V_function,\n",
    "    reward_ind,\n",
    "  ):\n",
    "    super(Q_Net, self).__init__()\n",
    "    self.V_function = V_function\n",
    "    self.reward_ind = reward_ind\n",
    "    \n",
    "  def forward(self, feature_batch):\n",
    "    v = self.V_function(feature_batch)\n",
    "    q = v + feature_batch[:, self.reward_ind][:, None].exp() - 1\n",
    "    return q\n",
    "\n",
    "\n",
    "class GNN_model(torch.nn.Module):\n",
    "  def __init__(\n",
    "    self,\n",
    "    num_input_features,\n",
    "    num_output_features\n",
    "  ):\n",
    "    super().__init__()\n",
    "    self.convs = nn.ModuleList([\n",
    "      GCNConv(num_input_features, 16),\n",
    "      GCNConv(16, 32),\n",
    "      GCNConv(32, 32),\n",
    "      GCNConv(32, 16),\n",
    "      GCNConv(16, num_output_features),\n",
    "    ])\n",
    "    self.dropout_probs = [\n",
    "      None,\n",
    "      None,\n",
    "      0.1,\n",
    "      0.3\n",
    "    ]\n",
    "\n",
    "  def forward(self, data_x, data_edge_index):\n",
    "    x, edge_index = data_x, data_edge_index\n",
    "    x = self.convs[0](x, edge_index)\n",
    "    for conv, prob in zip(self.convs[1:], self.dropout_probs):\n",
    "      x = F.relu(x)\n",
    "      if prob is not None:\n",
    "        x = F.dropout(x, p=prob, training=self.training)\n",
    "      x = conv(x, edge_index)\n",
    "    return x\n",
    "\n",
    "\n",
    "def get_mlp_setup(use_FFM=False,\n",
    "                  lr=1e-4,\n",
    "                  wd=0.05,\n",
    "                 ):\n",
    "    mlp = nn.Sequential(\n",
    "        nn.LazyLinear(512),\n",
    "        nn.ReLU(),\n",
    "        nn.Linear(512,256),\n",
    "        nn.LayerNorm(256),\n",
    "        FFM_layer(256) if use_FFM else nn.Identity(),\n",
    "        nn.LazyLinear(512),\n",
    "        nn.ReLU(),\n",
    "        nn.Linear(512,512),\n",
    "        nn.ReLU(),\n",
    "        nn.Linear(512,1),\n",
    "    ).to(device)\n",
    "    mlp_opt = torch.optim.AdamW(mlp.parameters(), lr=lr, weight_decay=wd, betas=(0.9, 0.999))\n",
    "    return mlp, mlp_opt\n",
    "  \n",
    "  \n",
    "def get_attn_setup(epochs, use_double=False):\n",
    "  attn_model = Attn_model().to(device)\n",
    "  if use_double:\n",
    "    attn_model = Double_attn_model().to(device)\n",
    "  opt = torch.optim.AdamW(attn_model.parameters(), lr=1e-4, weight_decay=1e-2,)\n",
    "  scheduler = torch.optim.lr_scheduler.LinearLR(opt, start_factor=1, end_factor=0.1, total_iters=epochs, verbose=True)\n",
    "  return attn_model, opt, scheduler\n",
    "\n",
    "\n",
    "def get_gnn_setup(num_input_features, num_output_features):\n",
    "  if not use_gnn:\n",
    "    return None, None\n",
    "  gnn_model = GNN_model(num_input_features, num_output_features).to(device)\n",
    "  opt = torch.optim.AdamW(gnn_model.parameters(), lr=3e-4, weight_decay=1e-2)\n",
    "  return gnn_model, opt\n",
    "\n",
    "\n",
    "def get_rnn_setup():\n",
    "  rnn_cell = V_cell()\n",
    "  opt =  torch.optim.AdamW(rnn_cell.parameters(), lr=3e-4, weight_decay=1e-2)\n",
    "  return rnn_cell, opt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Logger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "google.colab.output.setIframeHeight(0, true, {maxHeight: 600})"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "class Logger:\n",
    "  \"\"\"\n",
    "  Supporting class, to be expanded.\n",
    "  Intended to store logging utils and relevant data.\n",
    "  \"\"\"\n",
    "  def __init__(\n",
    "      self,\n",
    "      between_logs = 64,\n",
    "  ):\n",
    "    self.grad_a = None\n",
    "    self.grad_c = None\n",
    "    self.weight_a = None\n",
    "    self.weight_c = None\n",
    "    self.log_gamma = torch.tensor(0.95).to(device)\n",
    "    self.between_logs = between_logs\n",
    "    self.timer = {}\n",
    "\n",
    "  @torch.no_grad()\n",
    "  def link_models(self,):\n",
    "    self.grad_a = [p.grad.detach() for p in self.actor.parameters() if p.requires_grad]\n",
    "    self.weight_a = [p.detach() for p in self.actor.parameters()]\n",
    "    self.grad_c = [p.grad.detach() for p in self.critic.parameters() if p.requires_grad]\n",
    "    self.weight_c = [p.detach() for p in self.critic.parameters()]\n",
    "\n",
    "  @torch.no_grad()\n",
    "  def list_norm(self, l, p=2):\n",
    "    n = 0\n",
    "    for t in l:\n",
    "      n += t.detach().norm(p) ** p\n",
    "    return n.item() ** (1/p)\n",
    "\n",
    "  @torch.no_grad()\n",
    "  def list_cos_dist(self, a, b):\n",
    "    a_norm = self.list_norm(a, 2)\n",
    "    b_norm = self.list_norm(b, 2)\n",
    "    product = sum([torch.dot(torch.flatten(a[i]), torch.flatten(b[i])).item() for i in range(len(a))])\n",
    "    return product/(a_norm*b_norm)\n",
    "\n",
    "  @torch.no_grad()\n",
    "  def on_list(self, a, b, operation):\n",
    "    assert len(a) == len(b), 'lists lengths differ'\n",
    "    return [operation(a[i], b[i]) for i in range(len(a))]\n",
    "\n",
    "  @torch.no_grad()\n",
    "  def running_mean(self, a, b):\n",
    "    return [a[i].mul(self.log_gamma) + b[i].mul(1 - self.log_gamma) for i in range(len(a))]\n",
    "  \n",
    "  \n",
    "logger = Logger()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qBhLnmrnFDAu",
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 17
    },
    "id": "ov4TPknTgHSy",
    "outputId": "56487d39-1ae0-4e7a-a179-728941e4d9bf",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "google.colab.output.setIframeHeight(0, true, {maxHeight: 600})"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "class Trajectories:\n",
    "  \"\"\"\n",
    "  Contains all kinds of data in a form of tensor.\n",
    "  realized are raw and derived features of visited states.\n",
    "  queues is a list of each states' actions features.\n",
    "  Action and state embeddings are effectively the same, fyi. \n",
    "  \"\"\"\n",
    "  def __init__(self,\n",
    "               train_condition,\n",
    "               td_gamma=td_gamma,\n",
    "               use_gnn=use_gnn,\n",
    "               gnn_in_nfeatures=gnn_in_nfeatures,\n",
    "               gnn_out_nfeatures=gnn_out_nfeatures,\n",
    "              ):\n",
    "    self.train_condition = train_condition\n",
    "    self.td_gamma = td_gamma\n",
    "    self.use_gnn = use_gnn\n",
    "    self.gnn_in_nfeatures = gnn_in_nfeatures\n",
    "    self.gnn_out_nfeatures = gnn_out_nfeatures\n",
    "    self.j_file = None\n",
    "    self.feature_names, self.feature_names2ids = None, None\n",
    "    # dict of train tensors f, f_n, r, R, is_last, queue_len, chosen_acts, tr_id, graph_id +\n",
    "    # + list of queue tensors + list of block ids tensors + list of graphs data + list of previous probabilities tensors\n",
    "    self.realized, self.queues, self.queue_block_ids, self.graphs_data, self.prev_probs = None, None, None, None, None\n",
    "    # GAE critic estimates for each state estimated by trainer.GAE()\n",
    "    self.Psi = None\n",
    "    self.sampled_ids_list = []\n",
    "    self.sampled_queue_lengths_list = []\n",
    "    \n",
    "  \n",
    "  def gather_n_store(self, actor_model=None, gnn_model=None, json_path=json_path):\n",
    "    \"\"\"\n",
    "    Plays, collects trajectories into json, then transforms json to tensors\n",
    "    \"\"\"\n",
    "    self.update_data_on_path(actor_model, gnn_model, json_path)\n",
    "    self.store_from_json(json_path)\n",
    "    \n",
    "    \n",
    "  def evaluate_val_train(self, verbose=True,):\n",
    "    \"\"\"\n",
    "    Evaluates val and train subset\n",
    "    \"\"\"\n",
    "    log_val = self.evaluate_data(eval_condition = (lambda tr: not self.train_condition(tr)),\n",
    "                                 wandb_prefix = 'val', \n",
    "                                 verbose=verbose,)\n",
    "    log_train = self.evaluate_data(eval_condition = self.train_condition,\n",
    "                                   wandb_prefix = 'train',\n",
    "                                   verbose=verbose,)\n",
    "    return log_val, log_train\n",
    "  \n",
    "  \n",
    "  def store_from_json(self, json_path=json_path):\n",
    "    \"\"\"\n",
    "    Extracts trajectories from json to a torch-friendly form\n",
    "    \"\"\"\n",
    "    time_before = time()\n",
    "    self.j_file = json.load(open(json_path))\n",
    "    print('json loading time: ', time()-time_before)\n",
    "    self.feature_names = self.j_file['scheme'][0]\n",
    "    self.feature_names2ids = {self.feature_names[i]:i for i in range(len(self.feature_names))}\n",
    "    time_before = time()\n",
    "    self.realized, self.queues, self.queue_block_ids, self.graphs_data, self.prev_probs = self.j2torch(self.j_file)\n",
    "    print('j2torch time: ', time()-time_before)\n",
    "    self.Psi = None\n",
    "    \n",
    "  \n",
    "  def mean_code_length(self):\n",
    "    train_lines = 0\n",
    "    val_lines = 0\n",
    "    for tr in self.j_file['paths']:\n",
    "      if self.train_condition(tr):\n",
    "        train_lines += tr[3]\n",
    "      else:\n",
    "        val_lines += tr[3]\n",
    "    n_train_tr = self.get_properties()['number of traj-s']\n",
    "    n_val_tr = self.get_properties()['number of validation traj-s']\n",
    "    return train_lines/(n_train_tr-n_val_tr+1e-9), val_lines/(n_val_tr+1e-9)\n",
    "\n",
    "    \n",
    "  def j2torch(self, j_file):\n",
    "    \"\"\"\n",
    "    Transforms json to data tensors.\n",
    "    Queues are flipped for reasons related to batch truncation and padding. Actions numeration is changed accordingly.\n",
    "    \"\"\"\n",
    "    features, features_next, rewards, Returns, is_last, queue_lengths, chosen_actions, queues = [], [], [], [], [], [], [], []\n",
    "    graph_features, graph_edges, tr_ids, graph_ids, queue_block_ids = [], [], [], [], []\n",
    "    prev_probs = []\n",
    "    chosenStId_idx = self.j_file['scheme'].index('chosenStateId')\n",
    "    rewards_idx = self.j_file['scheme'].index('reward')\n",
    "    graphId_idx = self.j_file['scheme'].index('graphId')\n",
    "    blockIds_idx = self.j_file['scheme'].index('blockIds')\n",
    "    \n",
    "    logger.timer = {\n",
    "      'tr_prev_probs': 0,\n",
    "      'graph_features':0,\n",
    "      'tr_features':0,\n",
    "      'tr_graph_ids':0,\n",
    "      'tr_queues':0,\n",
    "      'cat graph features':0,\n",
    "      'graphs_data':0,\n",
    "    }\n",
    "    \n",
    "    tr_id = 0\n",
    "    for tr in self.j_file['paths']:\n",
    "      \n",
    "      time0=time()\n",
    "      if not self.train_condition(tr):\n",
    "        continue\n",
    "      if self.use_gnn:\n",
    "        graph_features.append(tr[4])\n",
    "        graph_edges.append(tr[5])\n",
    "      logger.timer['graph_features'] += time()-time0\n",
    "      \n",
    "      time0 = time()\n",
    "      tr_prev_probs = [torch.Tensor(tr[6][i]).flip(dims=[0]).to(device) for i in range(len(tr[6]))][1:] + [torch.ones(1).to(device)]\n",
    "      if len(tr_prev_probs) == 1:\n",
    "        tr_prev_probs = [torch.ones(len(tr[1][i][0])) for i in range(len(tr[1]))]\n",
    "      logger.timer['tr_prev_probs'] += time()-time0\n",
    "      \n",
    "      prev_probs += tr_prev_probs\n",
    "      tr = tr[1]\n",
    "      tr_rewards = [tr[i][rewards_idx] for i in range(len(tr))][1:] + [0]\n",
    "      # we use features as a state emb and reward is what we get the next step\n",
    "      rewards += tr_rewards\n",
    "      do_discount = torch.ones(len(tr))\n",
    "      if use_fork_discount:\n",
    "        is_cfg_fork_idx = self.j_file['scheme'].index('is_cfg_fork')\n",
    "        do_discount = [tr[i][is_cfg_fork_idx] for i in range(len(tr))]\n",
    "      tr_Returns = self.tr_rewards_to_returns(tr_rewards, do_discount)\n",
    "      Returns += tr_Returns\n",
    "      \n",
    "      tr_chosen_actions = [tr[i][chosenStId_idx] for i in range(len(tr))][1:] + [0]\n",
    "      chosen_actions += tr_chosen_actions\n",
    "      \n",
    "      time0=time()\n",
    "      tr_features = [tr[i][0][tr[i][chosenStId_idx]] for i in range(len(tr))]\n",
    "      is_last += [0]*(len(tr_features)-1) + [1]\n",
    "      features += tr_features\n",
    "      features_next += tr_features[1:] + [[-1]*len(self.feature_names)]\n",
    "      logger.timer['tr_features'] += time() - time0\n",
    "\n",
    "      tr_ids += [tr_id for i in range(len(tr))]\n",
    "      tr_id += 1\n",
    "\n",
    "      time0 = time()\n",
    "      if self.use_gnn:\n",
    "        tr_graph_ids = [tr[i][graphId_idx] for i in range(len(tr))]\n",
    "        graph_ids += tr_graph_ids\n",
    "        \n",
    "        tr_queue_block_ids = [torch.LongTensor(tr[i][blockIds_idx]).flip(dims=[0]).to(device) for i in range(len(tr))][1:] + [torch.LongTensor([-1]).to(device)]\n",
    "        queue_block_ids += tr_queue_block_ids\n",
    "      else:\n",
    "        graph_ids += [-1] * len(tr)\n",
    "      logger.timer['tr_graph_ids'] += time()-time0\n",
    "      \n",
    "      time0=time()\n",
    "      tr_queues = [torch.Tensor(tr[i][0]).flip(dims=[0]).to(device) for i in range(len(tr))][1:] + [torch.zeros_like(torch.Tensor([tr[0][0][0]])).to(device)]\n",
    "      logger.timer['tr_queues'] += time()-time0\n",
    "      \n",
    "      tr_queue_lengths = [len(q) for q in tr_queues]\n",
    "      queues += tr_queues\n",
    "      queue_lengths += tr_queue_lengths\n",
    "    rewards = torch.Tensor(rewards).to(device)\n",
    "    features = torch.Tensor(features).to(device)\n",
    "    features_next = torch.Tensor(features_next).to(device)\n",
    "    Returns = torch.Tensor(Returns).to(device)\n",
    "    is_last = torch.Tensor(is_last).to(device)\n",
    "    queue_lengths = torch.LongTensor(queue_lengths).to(device)\n",
    "    # we flip queue and numeration of actions\n",
    "    chosen_actions = queue_lengths - torch.LongTensor(chosen_actions).to(device) - 1\n",
    "    tr_ids = torch.LongTensor(tr_ids).to(device)\n",
    "    graph_ids = torch.LongTensor(graph_ids).to(device)\n",
    "      \n",
    "    time0 = time()\n",
    "    if self.use_gnn:\n",
    "      features = torch.cat((features, torch.zeros(len(features), gnn_out_nfeatures).to(device)), dim=1)\n",
    "      features_next = torch.cat((features_next, torch.zeros(len(features_next), gnn_out_nfeatures).to(device)), dim=1)\n",
    "      for i in range(len(queues)):\n",
    "        queues[i] = torch.cat((queues[i], torch.zeros(len(queues[i]), gnn_out_nfeatures).to(device)), dim=1)\n",
    "    logger.timer['cat graph features'] += time()-time0\n",
    "      \n",
    "    time0 = time()\n",
    "    graphs_data = []\n",
    "    for i in range(len(graph_features)):\n",
    "      graphs_data.append([GraphData(x=torch.Tensor(features).to(device), edge_index=torch.LongTensor(graph_edges[i]).to(device))\n",
    "                          for features in graph_features[i]])\n",
    "    logger.timer['graphs_data'] += time()-time0\n",
    "    print(logger.timer)\n",
    "      \n",
    "    realized = {\n",
    "      'features': features,\n",
    "      'features_next': features_next,\n",
    "      'rewards': rewards,\n",
    "      'Returns': Returns,\n",
    "      'is_last': is_last,\n",
    "      'queue_lengths': queue_lengths, \n",
    "      'chosen_actions': chosen_actions,\n",
    "      'tr_ids': tr_ids,\n",
    "      'graph_ids': graph_ids,\n",
    "    }\n",
    "    return realized, queues, queue_block_ids, graphs_data, prev_probs\n",
    "  \n",
    "\n",
    "  def get_n_train_states(self):\n",
    "    return len(self.realized['features'])\n",
    "\n",
    "  \n",
    "  def get_properties(self):\n",
    "    queue_lengths = np.array([q.shape[0] for q in self.queues])\n",
    "    longest_queue_ids = np.argmax(queue_lengths)\n",
    "    tr_lengths = np.array([len(tr[1]) for tr in self.j_file['paths']])\n",
    "    prop = {\n",
    "            'traj_length mean, median, max': (f'{tr_lengths.mean():.2f}', np.median(tr_lengths), tr_lengths.max()),\n",
    "            'queue max length, idx': (self.queues[longest_queue_ids].shape[0], longest_queue_ids),\n",
    "            'number of train states': self.get_n_train_states(),\n",
    "            'number of traj-s': len(self.j_file['paths']),\n",
    "            'number of validation traj-s': sum([not self.train_condition(tr) for tr in self.j_file['paths']]),\n",
    "           }\n",
    "    return prop\n",
    "  \n",
    "\n",
    "  def tr_rewards_to_returns(self, tr_rewards, do_discount):\n",
    "    tr_R = [0]*(len(tr_rewards))\n",
    "    for i in range(len(tr_rewards)-2, -1, -1):\n",
    "        tr_R[i] = tr_rewards[i] + (self.td_gamma**do_discount[i]) * tr_R[i+1]\n",
    "    return tr_R\n",
    "  \n",
    "  \n",
    "  def sample_ids(self, batch_size=batch_size):\n",
    "    \"\"\"\n",
    "    Assembles ids for several consiquent batches based on queues lengths.\n",
    "    \"\"\"\n",
    "    if len(self.sampled_ids_list) == 0:\n",
    "      sampled_ids = torch.LongTensor(random.choice(self.get_n_train_states(), size=batch_size*batch_accumulation_steps)).to(device)\n",
    "      sampled_queue_lengths = self.realized['queue_lengths'][sampled_ids]      \n",
    "      sampled_queue_lengths, sorting_ids = torch.sort(sampled_queue_lengths)\n",
    "      sampled_ids = sampled_ids[sorting_ids]\n",
    "      self.sampled_ids_list = list(torch.split(sampled_ids, batch_size))\n",
    "      self.sampled_queue_lengths_list = list(torch.split(sampled_queue_lengths, batch_size))\n",
    "    return self.sampled_ids_list.pop(0), self.sampled_queue_lengths_list.pop(0)\n",
    "      \n",
    "\n",
    "  def sample_batch(self, batch_size=batch_size):\n",
    "    ids, queue_lengths = self.sample_ids(batch_size=batch_size)    \n",
    "    sampled_realized = {k: self.realized[k][ids] for k in self.realized.keys()}  \n",
    "    sampled_queues = itemgetter(*list(ids))(self.queues)\n",
    "    sampled_prev_probs = itemgetter(*list(ids))(self.prev_probs)\n",
    "    padded_length = torch.minimum(queue_lengths.max(), torch.tensor(max_nactions))\n",
    "    queues_tensor = torch.zeros(batch_size, padded_length, len(self.queues[0][0])).to(device)\n",
    "    prev_probs_tensor = torch.zeros(batch_size, padded_length).to(device)\n",
    "    pad_mask = torch.ones(batch_size, padded_length).to(device)\n",
    "    if self.use_gnn:\n",
    "      sampled_queue_block_ids = itemgetter(*list(ids))(self.queue_block_ids)\n",
    "      queue_block_ids_tensor = torch.ones(batch_size, padded_length, dtype=torch.long).to(device) * (-1)\n",
    "    else:\n",
    "      sampled_queue_block_ids = None\n",
    "      queue_block_ids_tensor = None\n",
    "\n",
    "    start, end = torch.cuda.Event(enable_timing=True), torch.cuda.Event(enable_timing=True)\n",
    "    start.record()\n",
    "    \n",
    "    for i, q in enumerate(sampled_queues):\n",
    "      l = min(q.shape[0], padded_length)\n",
    "      queues_tensor[i, 0 : l, :] = q[: l, :]\n",
    "      pad_mask[i, 0 : l] = 0\n",
    "    pad_mask = pad_mask.bool()\n",
    "\n",
    "    if self.use_gnn:\n",
    "      for i, q in enumerate(sampled_queue_block_ids):\n",
    "        l = min(q.shape[0], padded_length)\n",
    "        queue_block_ids_tensor[i, 0 : l] = q[: l]\n",
    "    for i, p in enumerate(sampled_prev_probs):\n",
    "      l = min(p.shape[0], padded_length)\n",
    "      prev_probs_tensor[i, 0 : l] = p[: l]\n",
    "\n",
    "    end.record()    \n",
    "    maybe_sync()\n",
    "    logger.timer['sample inside loop'] += start.elapsed_time(end)/1000\n",
    "    \n",
    "    if not self.Psi is None:\n",
    "      Psi = self.Psi[ids]\n",
    "      return sampled_realized, Psi, queues_tensor, queue_block_ids_tensor, pad_mask, self.graphs_data, prev_probs_tensor\n",
    "    return sampled_realized, queues_tensor, queue_block_ids_tensor, pad_mask, self.graphs_data, prev_probs_tensor\n",
    "  \n",
    "  \n",
    "  def sample_realized_batch(self, n=batch_size):\n",
    "    ids = torch.tensor(random.choice(self.get_n_train_states(), size=n)).long()\n",
    "    sampled = {k: self.realized[k][ids] for k in self.realized.keys()}\n",
    "    return sampled\n",
    "  \n",
    "  \n",
    "  def update_data_on_path(self, actor_model=None, gnn_model=None, path=json_path):\n",
    "    \"\"\"\n",
    "    Communication with jar file on a server.\n",
    "    \"\"\"\n",
    "    if actor_model is None:\n",
    "      # use default heuristics\n",
    "      os.system('rm -f ../Game_env/actor_model.onnx')\n",
    "      os.system('rm -f ../Game_env/gnn_model.onnx')\n",
    "      algo_name = 'Heuristic'\n",
    "    else:\n",
    "      total_features_dim = features_dim\n",
    "      if hasattr(actor_model, 'sfmax'):\n",
    "        shape = [1, 1, total_features_dim]\n",
    "      else:\n",
    "        shape = [1, total_features_dim]\n",
    "      x = torch.randn(*shape, requires_grad=True).to(device)\n",
    "      torch_model = actor_model.eval()\n",
    "      torch_out = torch_model(x)\n",
    "      torch.onnx.export(torch_model,\n",
    "                        x,\n",
    "                        '../Game_env/actor_model.onnx',\n",
    "                        opset_version=15,\n",
    "                        export_params=True,\n",
    "                        input_names = ['input'],   # the model's input names\n",
    "                        output_names = ['output'],\n",
    "                        dynamic_axes={'input' : {0 : 'batch_size',\n",
    "                                                 1 : 'n_actions',\n",
    "                                                },    # variable length axes\n",
    "                                      'output' : {0 : 'batch_size',\n",
    "                                                  1 : 'n_actions',\n",
    "                                                },\n",
    "                                     },\n",
    "                        )\n",
    "      algo_name = 'NN'\n",
    "\n",
    "    if actor_model is not None and gnn_model is not None and self.use_gnn:\n",
    "      x_shape = [1, self.gnn_in_nfeatures]\n",
    "      edge_index_shape = [2, 1]\n",
    "      x = (torch.randn(*x_shape, requires_grad=True).to(device), torch.randint(0, 1, edge_index_shape).to(device))\n",
    "      torch_model = gnn_model.eval()\n",
    "      torch_out = torch_model(*x)\n",
    "      torch.onnx.export(torch_model,\n",
    "                        x,\n",
    "                        '../Game_env/gnn_model.onnx',\n",
    "                        opset_version=15,\n",
    "                        export_params=True,\n",
    "                        input_names = ['x', 'edge_index'],   # the model's input names\n",
    "                        output_names = ['output'],\n",
    "                        dynamic_axes={'x' : {0 : 'nodes_number'},    # variable length axes\n",
    "                                      'edge_index' : {1 : 'egdes_number'},\n",
    "                                     },\n",
    "                        )\n",
    "\n",
    "    time_before = time()\n",
    "    os.system(jar_command)\n",
    "    print(algo_name, 'data gathering time:', time() - time_before)\n",
    "\n",
    "  \n",
    "    \n",
    "  def evaluate_data(self,\n",
    "           eval_condition = None,\n",
    "           wandb_prefix = 'val',\n",
    "           verbose=True,\n",
    "           factors=torch.Tensor([1, td_gamma]),\n",
    "           ):\n",
    "    if eval_condition is None:\n",
    "        eval_condition = (lambda tr: not self.train_condition(tr))\n",
    "    rewards_idx = self.j_file['scheme'].index('reward')\n",
    "    for f in factors:\n",
    "      size = 0\n",
    "      tr_lengths = []\n",
    "      trs_R = []\n",
    "      for tr in self.j_file['paths']:\n",
    "        if not eval_condition(tr):\n",
    "          continue\n",
    "        tr=tr[1]\n",
    "        size += len(tr)\n",
    "        tr_lengths += [len(tr)]\n",
    "        # rewards list is not shifted, has a different purpose this time\n",
    "        tr_rewards = [tr[i][rewards_idx] for i in range(len(tr))]\n",
    "        trs_R += [0]\n",
    "        do_discount = torch.Tensor([1]*len(tr))\n",
    "        if use_fork_discount:\n",
    "          is_cfg_fork_idx = self.j_file['scheme'].index('is_cfg_fork')\n",
    "          do_discount = [tr[i][is_cfg_fork_idx] for i in range(len(tr))]\n",
    "        for i in range(len(tr_rewards)-1, -1, -1):\n",
    "          trs_R[-1] = tr_rewards[i] + (f ** do_discount[i]) * trs_R[-1]\n",
    "      log = {}\n",
    "      log[f'{wandb_prefix} size'] = size\n",
    "      log[f'{wandb_prefix}_eval/mean {f:.2f} discount '] = torch.Tensor(trs_R).mean()\n",
    "      log[f'{wandb_prefix}_eval/median {f:.2f} discount '] = torch.Tensor(trs_R).median()\n",
    "      log[f'{wandb_prefix} Return by trjs {f:.2f} (previous epoch)'] = wandb.Histogram(np_histogram=np.histogram(trs_R, bins=30, ))\n",
    "      # log[f'{wandb_prefix} lengths hist'] = wandb.Histogram(np_histogram=np.histogram(tr_lengths, bins=30, ))\n",
    "      log['code length train mean'], log['code length val mean'] = self.mean_code_length()\n",
    "      if verbose:\n",
    "          wandb.log(log.copy())\n",
    "      log['Returns'] = trs_R\n",
    "      log[f'{wandb_prefix} lengths'] = tr_lengths\n",
    "    return log"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tRSEdgzW9gFc",
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Trainer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 17
    },
    "id": "NsLLouOFgHQZ",
    "outputId": "fcc2f3f8-9c56-4071-ab7d-d944048bdc62",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "google.colab.output.setIframeHeight(0, true, {maxHeight: 600})"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "class NN_Trainer:\n",
    "  def __init__(\n",
    "      self,\n",
    "      NN_setup,\n",
    "      trajectories=None,\n",
    "      batch_size=batch_size,\n",
    "      n_batches=1000,\n",
    "      target_update_steps=15,\n",
    "      td_gamma=td_gamma,\n",
    "      clip_eps=2e-2,\n",
    "      use_gnn=True,\n",
    "      gnn_out_nfeatures=gnn_out_nfeatures,\n",
    "      ):\n",
    "    self.n_batches = n_batches\n",
    "    self.batch_number = -1\n",
    "    self.td_gamma = td_gamma\n",
    "    self.gae_gamma = 0.7\n",
    "    self.clip_eps = clip_eps\n",
    "    self.use_gnn = use_gnn\n",
    "    self.gnn_out_nfeatures = gnn_out_nfeatures\n",
    "    self.actor = NN_setup['actor']\n",
    "    self.actor_opt = NN_setup['actor_opt']\n",
    "    self.actor_sched = NN_setup['actor_sched']\n",
    "    self.prev_actor = copy.deepcopy(self.actor).eval()\n",
    "    self.critic = NN_setup['critic'].train()\n",
    "    self.target_critic = copy.deepcopy(self.critic).eval()\n",
    "    self.critic_opt = NN_setup['critic_opt']\n",
    "    self.gnn = NN_setup['gnn']\n",
    "    self.gnn_opt = NN_setup['gnn_opt']\n",
    "    self.gnn_zeros_tensor = torch.zeros(self.gnn_out_nfeatures).to(device)\n",
    "    self.trajectories = trajectories\n",
    "    self.batch_size = batch_size\n",
    "    self.target_update_steps = target_update_steps\n",
    "    self.log = {}\n",
    "\n",
    "  def run_gnn(self, tr_ids, graph_ids, graphs_data, gnn_features):\n",
    "    dataset = []\n",
    "    tr_graph_ids = list(set(zip(tr_ids, graph_ids)))\n",
    "    for tr_id, graph_id in tr_graph_ids:\n",
    "      dataset.append(graphs_data[tr_id][graph_id])\n",
    "    loader = GraphDataLoader(dataset, batch_size=256)\n",
    "    gnn_features_list = []\n",
    "    for batch_data in loader:\n",
    "      results = self.gnn(batch_data.x, batch_data.edge_index)\n",
    "      for i in range(batch_data.batch[-1] + 1):\n",
    "        gnn_features_list.append(results[batch_data.batch == i])\n",
    "    for i, (tr_id, graph_id) in enumerate(tr_graph_ids):\n",
    "      gnn_features[(tr_id, graph_id)] = gnn_features_list[i]\n",
    "\n",
    "  def add_gnn_features_actor(self, tr_ids, graph_ids, queue_block_ids_tensor, queues_tensor, gnn_features):\n",
    "    gnn_actor_tensor = []\n",
    "    for tr_id, graph_id, queue_block_ids in zip(tr_ids, graph_ids, queue_block_ids_tensor):\n",
    "      cur_gnn_features = gnn_features[(tr_id, graph_id)]\n",
    "      for block_id in queue_block_ids:\n",
    "        if block_id == -1:\n",
    "          gnn_actor_tensor.append(self.gnn_zeros_tensor)\n",
    "        else:\n",
    "          gnn_actor_tensor += [cur_gnn_features[block_id]]\n",
    "    gnn_actor_tensor = torch.cat(gnn_actor_tensor)\n",
    "    queues_shape = queues_tensor.shape\n",
    "    mask = torch.cat((torch.zeros(queues_shape[0], queues_shape[1], queues_shape[2] - self.gnn_out_nfeatures),\n",
    "                       torch.ones(queues_shape[0], queues_shape[1], self.gnn_out_nfeatures)), dim=2).bool().to(device)\n",
    "    queues_tensor[mask] = gnn_actor_tensor\n",
    "\n",
    "  def add_gnn_features_critic(self, tr_ids, graph_ids, features, features_next, gnn_features):\n",
    "    gnn_critic_list = []\n",
    "    for tr_id, graph_id in zip(tr_ids, graph_ids):\n",
    "      cur_gnn_features = gnn_features[(tr_id, graph_id)]\n",
    "      gnn_critic_list.append(torch.mean(cur_gnn_features, dim=0))\n",
    "    gnn_critic_tensor = torch.cat(gnn_critic_list)\n",
    "    gnn_critic_tensor_next = torch.cat(gnn_critic_list[1:] + [torch.zeros(self.gnn_out_nfeatures).to(device)])\n",
    "    mask = torch.cat((torch.zeros(features.shape[0], features.shape[1] - self.gnn_out_nfeatures),\n",
    "                       torch.ones(features.shape[0], self.gnn_out_nfeatures)), dim=1).bool().to(device)\n",
    "    features[mask] = gnn_critic_tensor\n",
    "    features_next[mask] = gnn_critic_tensor_next\n",
    "\n",
    "  def get_each_loss(self, sampled_batch,):\n",
    "    \"\"\"\n",
    "    Computes losses for actor, critic and exploration (loss_ent) within PPO algorithm.\n",
    "    Decisions were made to avoid python loops at all costs -- \n",
    "    varying action space is not particularly batch-friendly.    \n",
    "    \"\"\"\n",
    "    if self.trajectories.Psi is None:\n",
    "      sampled_realized, queues_tensor, queue_block_ids_tensor, pad_mask, graphs_data, prev_probs_tensor = sampled_batch\n",
    "    else:\n",
    "      sampled_realized, Psi, queues_tensor, queue_block_ids_tensor, pad_mask, graphs_data, prev_probs_tensor = sampled_batch\n",
    "    self.log['Returns mean'] = sampled_realized['Returns'].mean().item()\n",
    "    self.log['rewards mean'] = sampled_realized['rewards'].mean().item()\n",
    "    self.log['queue length max'] = sampled_realized['queue_lengths'].max().item()\n",
    "        \n",
    "    start, end = torch.cuda.Event(enable_timing=True), torch.cuda.Event(enable_timing=True)\n",
    "    start.record()\n",
    "\n",
    "    gnn_features = dict()\n",
    "    if self.use_gnn:\n",
    "      self.run_gnn(sampled_realized['tr_ids'].tolist(), sampled_realized['graph_ids'].tolist(), graphs_data, gnn_features)\n",
    "      self.add_gnn_features_actor(sampled_realized['tr_ids'].tolist(), sampled_realized['graph_ids'].tolist(),\n",
    "                                  queue_block_ids_tensor.tolist(), queues_tensor, gnn_features)\n",
    "      self.add_gnn_features_critic(sampled_realized['tr_ids'].tolist(), sampled_realized['graph_ids'].tolist(),\n",
    "                                   sampled_realized['features'], sampled_realized['features_next'], gnn_features)\n",
    "    probs = self.actor(queues_tensor, mask=pad_mask)\n",
    "    self.log['max prob mean'] = probs.max(dim=-1).values.mean().item()\n",
    "    self.log['40 max prob quantile'] = torch.quantile(probs.max(dim=-1).values, 0.4).item()\n",
    "    \n",
    "    end.record()    \n",
    "    maybe_sync()\n",
    "    logger.timer['probs+add_gnn_feature'] += start.elapsed_time(end)/1000\n",
    "\n",
    "    start, end = torch.cuda.Event(enable_timing=True), torch.cuda.Event(enable_timing=True)\n",
    "    start.record()\n",
    "\n",
    "    values = self.critic(sampled_realized['features']).squeeze(-1)\n",
    "    with torch.no_grad():\n",
    "      next_values = self.target_critic(sampled_realized['features_next']).squeeze(-1)\n",
    "    \n",
    "    end.record()    \n",
    "    maybe_sync()\n",
    "    logger.timer['values'] += start.elapsed_time(end)/1000\n",
    "        \n",
    "    t_hist = time()\n",
    "    self.log['V-func mean'] = torch.mean(values.detach()).item()\n",
    "    self.log['V-func stdev'] = torch.std(values.detach()).item()\n",
    "    # hist = wandb.Histogram(np_histogram=np.histogram(values.detach().to('cpu'), bins=40, ))\n",
    "    # self.log['V-func hist'] = hist\n",
    "    logger.timer['hist'] += time() - t_hist\n",
    "\n",
    "    # critic loss\n",
    "    t_critic_loss = time()\n",
    "    TD = values - ((sampled_realized['rewards'] + next_values.detach() * self.td_gamma) * (1-sampled_realized['is_last']))\n",
    "    MC = (values - sampled_realized['Returns']).abs().mean()/1000\n",
    "    loss_c = (TD**2).mean()/10 + MC\n",
    "    logger.timer['critic loss'] += time()-t_critic_loss\n",
    "\n",
    "    self.log['TD loss'] = (TD**2).mean().item()/10\n",
    "    self.log['MC loss'] = MC.item()\n",
    "    # hist = wandb.Histogram(np_histogram=np.histogram(TD.detach().to('cpu'), bins=20, ))\n",
    "    # self.log['TD hist'] = hist\n",
    "        \n",
    "    # entropy loss\n",
    "    t_entropy_loss = time()\n",
    "    \n",
    "    entropies = - probs * torch.log(torch.max(torch.tensor(1e-40), probs))\n",
    "    entropy_regularizer = torch.log(torch.minimum(sampled_realized['queue_lengths']+1, torch.tensor(max_nactions+1))).to(device)\n",
    "    entropy_by_state_reg = torch.sum(entropies, dim=-1) / entropy_regularizer\n",
    "    loss_ent = -entropy_by_state_reg.mean()\n",
    "        \n",
    "    logger.timer['entropy loss'] += time()-t_entropy_loss\n",
    "    \n",
    "    # actor loss\n",
    "    start, end = torch.cuda.Event(enable_timing=True), torch.cuda.Event(enable_timing=True)\n",
    "    start.record()\n",
    "    \n",
    "    probs_chosen = probs[get_ass_dope_ids(sampled_realized['chosen_actions'])].squeeze(-1)\n",
    "    prev_probs_chosen = prev_probs_tensor[get_ass_dope_ids(sampled_realized['chosen_actions'])].squeeze(-1)\n",
    "    ratios = (probs_chosen / (prev_probs_chosen.detach()+1e-4)).to(device)\n",
    "    \n",
    "    clipped = torch.clip(ratios, min=1-self.clip_eps, max=1+self.clip_eps)\n",
    "    Adv = - (TD * (1-sampled_realized['is_last'])).detach() # to not affect loss_a logs\n",
    "    self.log['Adv mean'] = Adv.sum() / (Adv.numel() - sampled_realized['is_last'].sum())\n",
    "    if self.trajectories.Psi is None:\n",
    "      loss_a = - torch.min(ratios*Adv, clipped*Adv).mean()\n",
    "    else:\n",
    "      loss_a = - torch.min(ratios*Psi, clipped*Psi).mean()\n",
    "    self.log['clipped to all'] = (clipped*Adv < ratios*Adv).long().sum().item() / ratios.numel()\n",
    "    self.log['ratios mean'] = ratios.mean().item()\n",
    "    end.record()    \n",
    "    maybe_sync()\n",
    "    logger.timer['actor loss'] += start.elapsed_time(end)/1000\n",
    "    return loss_a, loss_c, loss_ent\n",
    "  \n",
    "  \n",
    "  def critic_loss(self,\n",
    "               sampled_realized,\n",
    "    ):\n",
    "    \"\"\"\n",
    "    Temporal difference loss\n",
    "    \"\"\"\n",
    "    if self.use_gnn:\n",
    "      gnn_features = dict()\n",
    "      graphs_data = self.trajectories.graphs_data\n",
    "      self.run_gnn(sampled_realized['tr_ids'].tolist(), sampled_realized['graph_ids'].tolist(), graphs_data, gnn_features)\n",
    "      self.add_gnn_features_critic(sampled_realized['tr_ids'].tolist(), sampled_realized['graph_ids'].tolist(),\n",
    "                                   sampled_realized['features'], sampled_realized['features_next'], gnn_features)\n",
    "    values = self.critic(sampled_realized['features']).squeeze(-1)\n",
    "    with torch.no_grad():\n",
    "      next_values = self.target_critic(sampled_realized['features_next']).squeeze(-1)\n",
    "    self.log['V-func mean'] = torch.mean(values.detach()).item()\n",
    "    TD = values - ((sampled_realized['rewards'] + next_values * self.td_gamma) * (1-sampled_realized['is_last']))\n",
    "    MC = (values - sampled_realized['Returns']).abs().mean()/1000\n",
    "    critic_loss = (TD**2).mean()/10 + MC\n",
    "    self.log['TD loss'] = (TD**2).mean().item()/10\n",
    "    self.log['MC loss'] = MC.item()\n",
    "    return critic_loss\n",
    "  \n",
    "    \n",
    "  def learn_v(self, n_batches=None):\n",
    "    \"\"\"\n",
    "    Approximates V-function of previous policy by iterating over collected data.\n",
    "    \"\"\"\n",
    "    if n_batches is None:\n",
    "      n_batches = self.n_batches\n",
    "    for i in trange(n_batches):\n",
    "      self.batch_number = i\n",
    "      if self.batch_number % self.target_update_steps == 0:\n",
    "        self.target_critic = copy.deepcopy(self.critic).eval()\n",
    "      sampled_realized = self.trajectories.sample_realized_batch(n=2048)\n",
    "      loss = self.critic_loss(sampled_realized)\n",
    "      self.critic_opt.zero_grad()\n",
    "      loss.backward()\n",
    "      torch.nn.utils.clip_grad_norm_(self.critic.parameters(), 30)\n",
    "      self.critic_opt.step()\n",
    "      if self.batch_number % (logger.between_logs+1) == 0:\n",
    "        wandb.log(self.log)\n",
    "        self.log = {}\n",
    "\n",
    "\n",
    "  def learn_new_policy(self, prev_actor=None):\n",
    "    \"\"\"\n",
    "    Implements one learning cycle over collected dataset.\n",
    "    \"\"\"\n",
    "    if prev_actor is None:\n",
    "      self.prev_actor = copy.deepcopy(self.actor).eval()\n",
    "    else:\n",
    "      self.prev_actor = prev_actor\n",
    "      \n",
    "    logger.timer = {'probs+add_gnn_feature': 0,\n",
    "                    'values': 0,\n",
    "                    'hist': 0,\n",
    "                    'critic loss': 0,\n",
    "                    'entropy loss': 0,\n",
    "                    'actor loss': 0,\n",
    "                    'total loss': 0,\n",
    "                    'optimizers step': 0,\n",
    "                    'loss.backward': 0,\n",
    "                    'sample batch': 0,\n",
    "                    'sample ids': 0,\n",
    "                    'sample inside loop': 0,\n",
    "                    }\n",
    "    for i in trange(self.n_batches):\n",
    "      self.batch_number = i\n",
    "      if self.batch_number % self.target_update_steps == 0:\n",
    "        self.target_critic = copy.deepcopy(self.critic).eval()\n",
    "      \n",
    "      start, end = torch.cuda.Event(enable_timing=True), torch.cuda.Event(enable_timing=True)\n",
    "      start.record()\n",
    "      \n",
    "      sampled_batch = self.trajectories.sample_batch(self.batch_size)\n",
    "      \n",
    "      end.record()    \n",
    "      maybe_sync()\n",
    "      logger.timer['sample batch'] += start.elapsed_time(end)/1000\n",
    "      \n",
    "      start, end = torch.cuda.Event(enable_timing=True), torch.cuda.Event(enable_timing=True)\n",
    "      start.record()      \n",
    "      \n",
    "      loss_a, loss_c, loss_ent = self.get_each_loss(sampled_batch)\n",
    "      loss = (loss_a + loss_c + loss_ent/100) / batch_accumulation_steps\n",
    "\n",
    "      end.record()    \n",
    "      maybe_sync()\n",
    "      logger.timer['total loss'] += start.elapsed_time(end)/1000\n",
    "      \n",
    "      start, end = torch.cuda.Event(enable_timing=True), torch.cuda.Event(enable_timing=True)\n",
    "      start.record()   \n",
    "      \n",
    "      loss.backward()\n",
    "      \n",
    "      end.record()    \n",
    "      maybe_sync()\n",
    "      logger.timer['loss.backward'] += start.elapsed_time(end)/1000\n",
    "      \n",
    "      if self.batch_number % batch_accumulation_steps == 0:\n",
    "        t_optimizers_step = time()\n",
    "        torch.nn.utils.clip_grad_norm_(self.critic.parameters(), 30)\n",
    "        torch.nn.utils.clip_grad_norm_(self.actor.parameters(), 5)\n",
    "        self.actor_opt.step()\n",
    "        self.critic_opt.step()\n",
    "        if use_gnn:\n",
    "          self.gnn_opt.step()\n",
    "          self.log.update({\n",
    "            'grad gnn': logger.list_norm([p.grad for p in self.gnn.parameters() if p.requires_grad], 2),\n",
    "            'weight gnn': logger.list_norm([p for p in self.gnn.parameters() if p.requires_grad], 2),\n",
    "        })\n",
    "        self.log.update({\n",
    "            'grad actor': logger.list_norm([p.grad for p in self.actor.parameters() if p.requires_grad], 2),\n",
    "            'grad critic': logger.list_norm([p.grad for p in self.critic.parameters() if p.requires_grad], 2),\n",
    "        })\n",
    "        self.critic_opt.zero_grad()\n",
    "        self.actor_opt.zero_grad()\n",
    "        if use_gnn:\n",
    "          self.gnn_opt.zero_grad()\n",
    "        logger.timer['optimizers step'] += time()-t_optimizers_step\n",
    "        \n",
    "\n",
    "      if self.batch_number % (logger.between_logs+1) == 0:\n",
    "        self.log.update({\n",
    "            'loss actor': loss_a.item(),\n",
    "            'loss critic': loss_c.item(),\n",
    "            '-entropy by log(n)': loss_ent.item(),\n",
    "            'weight actor': logger.list_norm([p for p in self.actor.parameters() if p.requires_grad], 2),\n",
    "            'weight critic': logger.list_norm([p for p in self.critic.parameters() if p.requires_grad], 2),\n",
    "        })\n",
    "        wandb.log(self.log)\n",
    "        self.log = {}\n",
    "    self.actor_sched.step()\n",
    "        \n",
    "        \n",
    "  @torch.no_grad()      \n",
    "  def compute_GAE(self, critic_to_use=None):\n",
    "    \"\"\"\n",
    "    Computes GAE with passed/current critic.\n",
    "    GAEs could be used instead of Advantages in PPO actor loss\n",
    "    \"\"\"\n",
    "    if critic_to_use is None:\n",
    "      critic_to_use = copy.deepcopy(self.critic).eval()\n",
    "    features = self.trajectories.realized['features']\n",
    "    features_next = self.trajectories.realized['features_next']\n",
    "    rewards = self.trajectories.realized['rewards']\n",
    "    is_last = self.trajectories.realized['is_last']\n",
    "    Adv1 = []\n",
    "    ids_list = list(torch.split(torch.LongTensor(np.arange(len(is_last))), 4096))\n",
    "    for batch_ids in ids_list:\n",
    "      values = critic_to_use(features[batch_ids]).squeeze(-1)\n",
    "      values_next = critic_to_use(features_next[batch_ids]).squeeze(-1)\n",
    "      TD = values - ((rewards[batch_ids] + values_next * self.td_gamma) * (1-is_last[batch_ids]))\n",
    "      batch_Adv = - TD * (1-is_last[batch_ids])\n",
    "      Adv1 += [batch_Adv]\n",
    "    Adv1 = torch.cat(Adv1, dim=0)\n",
    "    Psi = torch.zeros_like(Adv1)\n",
    "    \n",
    "    for i in range(len(Adv1)-1, -1, -1):\n",
    "      if is_last[i]:\n",
    "        continue\n",
    "      Psi[i] = Psi[i+1] * self.gae_gamma * self.td_gamma + Adv1[i]\n",
    "    self.trajectories.Psi = Psi      \n",
    "    wandb.log({'Psi mean': Psi.mean().item(),\n",
    "               'Psi 95 perc': torch.quantile(Psi, 0.95).item(),\n",
    "               'Adv mean': Adv1.mean().item(),\n",
    "              })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "google.colab.output.setIframeHeight(0, true, {maxHeight: 600})"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "class RNN_Trainer():\n",
    "  \"\"\"\n",
    "  Learns state history representation via a proxy task of V-function approximation.\n",
    "  \"\"\"\n",
    "  def __init__(self, v_cell, optimizer, trajectories, loss_horizon=10, rnn_batch_size=32):\n",
    "    self.rnn_cell = v_cell\n",
    "    self.optimizer = optimizer\n",
    "    self.loss_horizon = loss_horizon\n",
    "    self.retain_graph = True\n",
    "    self.trjs = trajectories\n",
    "    self.log = {}\n",
    "    \n",
    "  def sample_ids_pairs(self, features_by_trjs, rnn_batch_size, n_steps):\n",
    "    \"\"\"\n",
    "    Returns [n_steps] list with [rnn_batch_size, 2] tensors\n",
    "    of pairs (traj idx, position in traj for rnn to start from)\n",
    "    \"\"\"\n",
    "    n_trjs = len(features_by_trjs)\n",
    "    residual_lengths = torch.tensor([len(f)-self.loss_horizon for f in features_by_trjs])\n",
    "    sampling_weights = torch.log(residual_lengths) / torch.log(residual_lengths).sum()\n",
    "    trjs_ids = torch.tensor(np.random.choice(np.arange(n_trjs), size=(n_steps, rnn_batch_size), p=sampling_weights))\n",
    "    position_samples = torch.rand(n_steps, rnn_batch_size)\n",
    "    residual_lengths_forall = torch.take(residual_lengths, trjs_ids)\n",
    "    start_ids = (residual_lengths_forall*position_samples).long()\n",
    "    stacked = torch.stack([trjs_ids, start_ids], dim=-1).to(device)\n",
    "    return list(stacked)\n",
    "  \n",
    "  def train(self, n_steps=1000, rnn_batch_size=32):\n",
    "    is_last_ids = torch.nonzero(self.trjs.realized['is_last']).squeeze()\n",
    "    all_train_trjs_lengths = is_last_ids - torch.cat([torch.tensor([-1]).to(device), is_last_ids[:-1]])\n",
    "    not_long_enough_ids = (train_trjs_lengths < self.loss_horizon + 3).nonzero().squeeze()\n",
    "    features_by_trjs = list(torch.split(self.trjs.realized['features'], list(all_train_trjs_lengths)))\n",
    "    Returns_by_trjs = list(torch.split(self.trjs.realized['Returns'], list(all_train_trjs_lengths)))\n",
    "    for i in list(not_long_enough_ids).reverse():\n",
    "      # we train ony on long enough trajectories\n",
    "      popped = features_by_trjs.pop(i)\n",
    "      Returns_by_trjs.pop(i)\n",
    "      assert len(popped) < self.loss_horizon\n",
    "    sampled_ids = sample_ids_pairs(features_by_trjs, rnn_batch_size, n_steps)\n",
    "    for step in range(n_steps):\n",
    "      batch_ids = sampled_ids.pop(0)\n",
    "      inputs = torch.zeros(rnn_batch_size, self.loss_horizon, features_dim).to(device)\n",
    "      targets = torch.zeros(rnn_batch_size, self.loss_horizon, 1).to(device)\n",
    "      for b in range(rnn_batch_size):\n",
    "        inputs[b] = features_by_trjs[batch_ids[b,0]][batch_ids[b,1]: batch_ids[b,1] + self.loss_horizon]\n",
    "        targets[b] = Returns_by_trjs[batch_ids[b,0]][batch_ids[b,1]: batch_ids[b,1] + self.loss_horizon][:, None]\n",
    "      states = [torch.zeros(2*self.rnn_cell.num_layers, rnn_batch_size, self.rnn_cell.hidden_size).to(device)]\n",
    "      Vs = []\n",
    "      for rnn_step in range(self.loss_horizon):\n",
    "        v, new_state = self.rnn_cell(inputs[rnn_step], states[-1])\n",
    "        states += [new_state]\n",
    "        Vs += [v]\n",
    "      abs_difs = (torch.cat(Vs) - targets).abs()\n",
    "      assert abs_difs.shape == (rnn_batch_size, self.loss_horizon, 1)\n",
    "      loss_weights = torch.arange(self.loss_horizon)**1.4 / (torch.arange(self.loss_horizon)**1.4).sum()\n",
    "      loss = (abs_difs * loss_weights[:, None].to(device)).mean()\n",
    "      self.log['rnn MC abs loss'] = loss.item()\n",
    "      self.log['rnn V mean'] = torch.cat(Vs).mean().item()\n",
    "      self.optimizer.zero_grad()\n",
    "      loss.backward()\n",
    "      self.optimizer.step()\n",
    "      \n",
    "  @torch.no_grad()\n",
    "  def collect_rnn_features(self):\n",
    "    \"\"\"\n",
    "    Collects rnn hidden and V for every state in train dataset \n",
    "    \"\"\"\n",
    "    features = self.trjs.realized['features']\n",
    "    is_last = self.trjs.realized['is_last']\n",
    "    hid_list = []\n",
    "    v_list = []\n",
    "    init_state = torch.zeros(2*self.rnn_cell.num_layers, 1, self.rnn_cell.hidden_size).to(device)\n",
    "    state = init_state\n",
    "    for i, f in enumerate(features):\n",
    "      v, state = self.rnn_cell(f[None, :], state)\n",
    "      hid = state[2].squeeze(0)\n",
    "      hid_list += [hid.detach()]\n",
    "      v_list += [v.detach()]\n",
    "      if is_last[i]:\n",
    "        state = init_state\n",
    "    self.traj.realized['rnn_features'] = torch.stack(hid_list, dim=0)\n",
    "    self.traj.realized['rnn_v'] = torch.stack(v_list, dim=0)\n",
    "    \n",
    "  @torch.no_grad()\n",
    "  def concat_rnn_features(self):\n",
    "    \"\"\"\n",
    "    Concatenates state history embedding to embedding of that state and to embeddings of corresponding actions \n",
    "    \"\"\"\n",
    "    realized = self.trjs.realized\n",
    "    rnn_related = torch.cat([realized['rnn_features'], realized['rnn_v']], dim=-1)\n",
    "    realized['features'] = torch.cat([realized['features'], rnn_related], dim=-1)\n",
    "    queues = self.trjs.queues\n",
    "    time_before = time()\n",
    "    for i in range(len(queues)):\n",
    "      queues[i] = torch.cat([queues[i], rnn_related[i].repeat(len(queues[i]), 1)], dim=-1)\n",
    "    print('Concating rnn features to queues: ', time()-time_before)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "google.colab.output.setIframeHeight(0, true, {maxHeight: 600})"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def get_ass_dope_ids(l):\n",
    "  l = l.long()\n",
    "  if len(l.shape) == 1:\n",
    "    l = l[:, None]\n",
    "  ind = torch.LongTensor(np.indices(l.shape))\n",
    "  ind[-1] = l\n",
    "  return tuple(ind)\n",
    "\n",
    "def consumption_percent(epoch):\n",
    "  return 50\n",
    "\n",
    "def get_clip_eps(epoch):\n",
    "  if epoch < 5:\n",
    "    c = 0.5\n",
    "  elif epoch < 25:\n",
    "    c = 0.2\n",
    "  else:\n",
    "    c = 0.05\n",
    "  return c"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UX4jPlzD9gFd",
    "tags": []
   },
   "source": [
    "### Procedure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 124
    },
    "id": "Bi2uaButgHOM",
    "outputId": "ac74fdf1-0fb8-4613-b567-6b8b14dec89b",
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "google.colab.output.setIframeHeight(0, true, {maxHeight: 600})"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusting learning rate of group 0 to 2.0000e-05.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.15.8 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.7"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/st-andrey-podivilov/Notebooks/wandb/run-20230818_140043-sd2u229n</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/andrey_podivilov/PS/runs/sd2u229n' target=\"_blank\">tune double no_gnn</a></strong> to <a href='https://wandb.ai/andrey_podivilov/PS' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/andrey_podivilov/PS' target=\"_blank\">https://wandb.ai/andrey_podivilov/PS</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/andrey_podivilov/PS/runs/sd2u229n' target=\"_blank\">https://wandb.ai/andrey_podivilov/PS/runs/sd2u229n</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NN data gathering time: 139.4162735939026\n",
      "json loading time:  6.077685594558716\n",
      "{'tr_prev_probs': 3.1756234169006348, 'graph_features': 0.0012946128845214844, 'tr_features': 0.02842998504638672, 'tr_graph_ids': 0.002512693405151367, 'tr_queues': 4.312460660934448, 'cat graph features': 5.0067901611328125e-06, 'graphs_data': 2.47955322265625e-05}\n",
      "j2torch time:  10.298267841339111\n",
      "{'traj_length mean, median, max': ('169.10', 31.0, 1501), 'queue max length, idx': (48, 78237), 'number of train states': 103120, 'number of traj-s': 788, 'number of validation traj-s': 170}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 250/250 [00:40<00:00,  6.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusting learning rate of group 0 to 1.9820e-05.\n",
      "NN data gathering time: 96.91763687133789\n",
      "json loading time:  3.2417681217193604\n",
      "{'tr_prev_probs': 1.5628864765167236, 'graph_features': 0.0006070137023925781, 'tr_features': 0.013328075408935547, 'tr_graph_ids': 0.00083160400390625, 'tr_queues': 2.2015445232391357, 'cat graph features': 5.9604644775390625e-06, 'graphs_data': 4.5299530029296875e-06}\n",
      "j2torch time:  5.411961793899536\n",
      "{'traj_length mean, median, max': ('169.28', 28.5, 1501), 'queue max length, idx': (42, 20090), 'number of train states': 50887, 'number of traj-s': 394, 'number of validation traj-s': 85}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 250/250 [00:37<00:00,  6.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusting learning rate of group 0 to 1.9640e-05.\n",
      "NN data gathering time: 98.65009045600891\n",
      "json loading time:  4.268360614776611\n",
      "{'tr_prev_probs': 2.3114044666290283, 'graph_features': 0.0009388923645019531, 'tr_features': 0.022204160690307617, 'tr_graph_ids': 0.0013439655303955078, 'tr_queues': 2.029927968978882, 'cat graph features': 7.62939453125e-06, 'graphs_data': 1.049041748046875e-05}\n",
      "j2torch time:  6.068872451782227\n",
      "{'traj_length mean, median, max': ('187.25', 31.0, 1501), 'queue max length, idx': (65, 39579), 'number of train states': 53440, 'number of traj-s': 387, 'number of validation traj-s': 92}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 250/250 [00:43<00:00,  5.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusting learning rate of group 0 to 1.9460e-05.\n",
      "NN data gathering time: 91.03038382530212\n",
      "json loading time:  4.940057754516602\n",
      "{'tr_prev_probs': 1.9303224086761475, 'graph_features': 0.0011477470397949219, 'tr_features': 0.01940131187438965, 'tr_graph_ids': 0.0014498233795166016, 'tr_queues': 2.23753023147583, 'cat graph features': 8.344650268554688e-06, 'graphs_data': 1.1920928955078125e-05}\n",
      "j2torch time:  6.115119695663452\n",
      "{'traj_length mean, median, max': ('216.58', 33.0, 1501), 'queue max length, idx': (51, 17236), 'number of train states': 58940, 'number of traj-s': 382, 'number of validation traj-s': 87}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 250/250 [00:40<00:00,  6.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusting learning rate of group 0 to 1.9280e-05.\n",
      "NN data gathering time: 94.44353818893433\n",
      "json loading time:  5.506159782409668\n",
      "{'tr_prev_probs': 1.6824486255645752, 'graph_features': 0.0008022785186767578, 'tr_features': 0.016710996627807617, 'tr_graph_ids': 0.0011818408966064453, 'tr_queues': 1.9804906845092773, 'cat graph features': 1.0013580322265625e-05, 'graphs_data': 1.049041748046875e-05}\n",
      "j2torch time:  5.400115013122559\n",
      "{'traj_length mean, median, max': ('186.63', 33.0, 1501), 'queue max length, idx': (72, 39454), 'number of train states': 53173, 'number of traj-s': 385, 'number of validation traj-s': 83}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 250/250 [00:40<00:00,  6.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusting learning rate of group 0 to 1.9100e-05.\n",
      "NN data gathering time: 96.78603339195251\n",
      "json loading time:  4.197582721710205\n",
      "{'tr_prev_probs': 1.9023914337158203, 'graph_features': 0.0011103153228759766, 'tr_features': 0.0191497802734375, 'tr_graph_ids': 0.001455545425415039, 'tr_queues': 2.181835174560547, 'cat graph features': 5.9604644775390625e-06, 'graphs_data': 5.7220458984375e-06}\n",
      "j2torch time:  6.036898374557495\n",
      "{'traj_length mean, median, max': ('207.24', 29.0, 1473), 'queue max length, idx': (44, 12773), 'number of train states': 58787, 'number of traj-s': 395, 'number of validation traj-s': 91}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 250/250 [00:38<00:00,  6.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusting learning rate of group 0 to 1.8920e-05.\n",
      "NN data gathering time: 96.71084570884705\n",
      "json loading time:  4.300457954406738\n",
      "{'tr_prev_probs': 1.6048972606658936, 'graph_features': 0.0007472038269042969, 'tr_features': 0.01572442054748535, 'tr_graph_ids': 0.0011725425720214844, 'tr_queues': 1.8683140277862549, 'cat graph features': 1.1205673217773438e-05, 'graphs_data': 1.0251998901367188e-05}\n",
      "j2torch time:  5.108102560043335\n",
      "{'traj_length mean, median, max': ('179.42', 26.0, 1501), 'queue max length, idx': (84, 38576), 'number of train states': 50677, 'number of traj-s': 388, 'number of validation traj-s': 84}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 250/250 [00:44<00:00,  5.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusting learning rate of group 0 to 1.8740e-05.\n",
      "NN data gathering time: 97.47627472877502\n",
      "json loading time:  3.760350465774536\n",
      "{'tr_prev_probs': 5.11362886428833, 'graph_features': 0.00106048583984375, 'tr_features': 0.01769423484802246, 'tr_graph_ids': 0.0013127326965332031, 'tr_queues': 7.372008323669434, 'cat graph features': 5.0067901611328125e-06, 'graphs_data': 4.291534423828125e-06}\n",
      "j2torch time:  14.293853521347046\n",
      "{'traj_length mean, median, max': ('175.12', 26.0, 1501), 'queue max length, idx': (48, 43514), 'number of train states': 57636, 'number of traj-s': 394, 'number of validation traj-s': 80}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 250/250 [01:18<00:00,  3.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusting learning rate of group 0 to 1.8560e-05.\n",
      "NN data gathering time: 87.77162981033325\n",
      "json loading time:  3.9571685791015625\n",
      "{'tr_prev_probs': 9.034733772277832, 'graph_features': 0.0011374950408935547, 'tr_features': 0.01820087432861328, 'tr_graph_ids': 0.001394510269165039, 'tr_queues': 9.997941732406616, 'cat graph features': 6.198883056640625e-06, 'graphs_data': 1.049041748046875e-05}\n",
      "j2torch time:  20.998766899108887\n",
      "{'traj_length mean, median, max': ('199.04', 32.0, 1344), 'queue max length, idx': (40, 46117), 'number of train states': 60459, 'number of traj-s': 399, 'number of validation traj-s': 82}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 250/250 [01:16<00:00,  3.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusting learning rate of group 0 to 1.8380e-05.\n",
      "NN data gathering time: 103.66037964820862\n",
      "json loading time:  3.764714479446411\n",
      "{'tr_prev_probs': 1.6602635383605957, 'graph_features': 0.0006389617919921875, 'tr_features': 0.015609264373779297, 'tr_graph_ids': 0.0011925697326660156, 'tr_queues': 1.8785905838012695, 'cat graph features': 5.9604644775390625e-06, 'graphs_data': 5.4836273193359375e-06}\n",
      "j2torch time:  5.202850103378296\n",
      "{'traj_length mean, median, max': ('182.33', 36.0, 1501), 'queue max length, idx': (49, 2959), 'number of train states': 54049, 'number of traj-s': 392, 'number of validation traj-s': 88}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 250/250 [00:39<00:00,  6.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusting learning rate of group 0 to 1.8200e-05.\n",
      "NN data gathering time: 101.9282820224762\n",
      "json loading time:  4.455860137939453\n",
      "{'tr_prev_probs': 1.5757029056549072, 'graph_features': 0.0007762908935546875, 'tr_features': 0.015395641326904297, 'tr_graph_ids': 0.0011866092681884766, 'tr_queues': 1.7718017101287842, 'cat graph features': 4.291534423828125e-06, 'graphs_data': 3.814697265625e-06}\n",
      "j2torch time:  5.014542818069458\n",
      "{'traj_length mean, median, max': ('191.82', 30.0, 1501), 'queue max length, idx': (52, 14997), 'number of train states': 50010, 'number of traj-s': 374, 'number of validation traj-s': 85}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 250/250 [00:39<00:00,  6.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusting learning rate of group 0 to 1.8020e-05.\n",
      "NN data gathering time: 112.91390657424927\n",
      "json loading time:  3.806763172149658\n",
      "{'tr_prev_probs': 1.602522850036621, 'graph_features': 0.0008635520935058594, 'tr_features': 0.01526498794555664, 'tr_graph_ids': 0.001107931137084961, 'tr_queues': 1.8454291820526123, 'cat graph features': 6.198883056640625e-06, 'graphs_data': 8.58306884765625e-06}\n",
      "j2torch time:  5.048805475234985\n",
      "{'traj_length mean, median, max': ('180.13', 31.0, 1501), 'queue max length, idx': (64, 43163), 'number of train states': 52045, 'number of traj-s': 384, 'number of validation traj-s': 88}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 250/250 [00:39<00:00,  6.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusting learning rate of group 0 to 1.7840e-05.\n",
      "NN data gathering time: 90.04598498344421\n",
      "json loading time:  3.9676709175109863\n",
      "{'tr_prev_probs': 1.800954818725586, 'graph_features': 0.0007832050323486328, 'tr_features': 0.01719522476196289, 'tr_graph_ids': 0.0012803077697753906, 'tr_queues': 2.0939414501190186, 'cat graph features': 5.0067901611328125e-06, 'graphs_data': 5.0067901611328125e-06}\n",
      "j2torch time:  6.180996894836426\n",
      "{'traj_length mean, median, max': ('188.29', 27.5, 1501), 'queue max length, idx': (59, 39305), 'number of train states': 58360, 'number of traj-s': 394, 'number of validation traj-s': 84}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 250/250 [00:38<00:00,  6.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusting learning rate of group 0 to 1.7660e-05.\n",
      "NN data gathering time: 99.60273265838623\n",
      "json loading time:  5.195897817611694\n",
      "{'tr_prev_probs': 1.831662654876709, 'graph_features': 0.0007834434509277344, 'tr_features': 0.017466306686401367, 'tr_graph_ids': 0.0012753009796142578, 'tr_queues': 2.7845561504364014, 'cat graph features': 2.4318695068359375e-05, 'graphs_data': 9.775161743164062e-06}\n",
      "j2torch time:  6.475531101226807\n",
      "{'traj_length mean, median, max': ('207.09', 28.0, 1501), 'queue max length, idx': (67, 19995), 'number of train states': 58674, 'number of traj-s': 387, 'number of validation traj-s': 92}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 250/250 [00:41<00:00,  6.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusting learning rate of group 0 to 1.7480e-05.\n",
      "NN data gathering time: 99.77912473678589\n",
      "json loading time:  2.657055139541626\n",
      "{'tr_prev_probs': 1.3577995300292969, 'graph_features': 0.0007417201995849609, 'tr_features': 0.0122833251953125, 'tr_graph_ids': 0.000949859619140625, 'tr_queues': 1.5210909843444824, 'cat graph features': 5.9604644775390625e-06, 'graphs_data': 5.245208740234375e-06}\n",
      "j2torch time:  4.2996344566345215\n",
      "{'traj_length mean, median, max': ('146.83', 32.0, 1420), 'queue max length, idx': (39, 8885), 'number of train states': 44104, 'number of traj-s': 386, 'number of validation traj-s': 92}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 250/250 [00:37<00:00,  6.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusting learning rate of group 0 to 1.7300e-05.\n",
      "NN data gathering time: 91.68265724182129\n",
      "json loading time:  4.002163648605347\n",
      "{'tr_prev_probs': 1.7837085723876953, 'graph_features': 0.0009870529174804688, 'tr_features': 0.017519235610961914, 'tr_graph_ids': 0.0011873245239257812, 'tr_queues': 2.1166000366210938, 'cat graph features': 5.245208740234375e-06, 'graphs_data': 9.298324584960938e-06}\n",
      "j2torch time:  5.672453165054321\n",
      "{'traj_length mean, median, max': ('173.46', 29.0, 1501), 'queue max length, idx': (62, 45438), 'number of train states': 56728, 'number of traj-s': 377, 'number of validation traj-s': 80}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 250/250 [00:41<00:00,  6.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusting learning rate of group 0 to 1.7120e-05.\n",
      "NN data gathering time: 85.66029906272888\n",
      "json loading time:  3.216754913330078\n",
      "{'tr_prev_probs': 1.831850290298462, 'graph_features': 0.0009720325469970703, 'tr_features': 0.016774415969848633, 'tr_graph_ids': 0.0012693405151367188, 'tr_queues': 2.378387451171875, 'cat graph features': 2.7418136596679688e-05, 'graphs_data': 9.5367431640625e-06}\n",
      "j2torch time:  6.066020965576172\n",
      "{'traj_length mean, median, max': ('182.07', 31.5, 1472), 'queue max length, idx': (33, 20050), 'number of train states': 58025, 'number of traj-s': 406, 'number of validation traj-s': 94}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 250/250 [00:36<00:00,  6.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusting learning rate of group 0 to 1.6940e-05.\n",
      "NN data gathering time: 98.01767683029175\n",
      "json loading time:  3.3071131706237793\n",
      "{'tr_prev_probs': 2.063119649887085, 'graph_features': 0.0007266998291015625, 'tr_features': 0.015488386154174805, 'tr_graph_ids': 0.0011744499206542969, 'tr_queues': 1.8206398487091064, 'cat graph features': 5.7220458984375e-06, 'graphs_data': 5.245208740234375e-06}\n",
      "j2torch time:  5.509599447250366\n",
      "{'traj_length mean, median, max': ('173.43', 33.0, 1501), 'queue max length, idx': (76, 37454), 'number of train states': 50409, 'number of traj-s': 382, 'number of validation traj-s': 85}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 250/250 [00:42<00:00,  5.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusting learning rate of group 0 to 1.6760e-05.\n",
      "NN data gathering time: 90.06292486190796\n",
      "json loading time:  3.2592175006866455\n",
      "{'tr_prev_probs': 1.6515681743621826, 'graph_features': 0.0005984306335449219, 'tr_features': 0.015193462371826172, 'tr_graph_ids': 0.0011911392211914062, 'tr_queues': 1.8352909088134766, 'cat graph features': 5.9604644775390625e-06, 'graphs_data': 4.76837158203125e-06}\n",
      "j2torch time:  5.128601789474487\n",
      "{'traj_length mean, median, max': ('181.06', 28.0, 1501), 'queue max length, idx': (31, 3718), 'number of train states': 54154, 'number of traj-s': 390, 'number of validation traj-s': 88}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 250/250 [00:37<00:00,  6.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusting learning rate of group 0 to 1.6580e-05.\n",
      "NN data gathering time: 99.36723351478577\n",
      "json loading time:  3.5874202251434326\n",
      "{'tr_prev_probs': 1.9889895915985107, 'graph_features': 0.0010306835174560547, 'tr_features': 0.017228126525878906, 'tr_graph_ids': 0.0012621879577636719, 'tr_queues': 2.3572640419006348, 'cat graph features': 5.7220458984375e-06, 'graphs_data': 8.821487426757812e-06}\n",
      "j2torch time:  6.266549825668335\n",
      "{'traj_length mean, median, max': ('167.77', 26.0, 1501), 'queue max length, idx': (64, 34580), 'number of train states': 50492, 'number of traj-s': 390, 'number of validation traj-s': 86}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 250/250 [00:41<00:00,  5.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusting learning rate of group 0 to 1.6400e-05.\n",
      "NN data gathering time: 97.91637325286865\n",
      "json loading time:  4.064199209213257\n",
      "{'tr_prev_probs': 2.4734601974487305, 'graph_features': 0.0007157325744628906, 'tr_features': 0.01978135108947754, 'tr_graph_ids': 0.0014514923095703125, 'tr_queues': 2.560220718383789, 'cat graph features': 5.7220458984375e-06, 'graphs_data': 3.5762786865234375e-06}\n",
      "j2torch time:  7.111647844314575\n",
      "{'traj_length mean, median, max': ('185.88', 31.0, 1387), 'queue max length, idx': (40, 47181), 'number of train states': 59621, 'number of traj-s': 391, 'number of validation traj-s': 85}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 250/250 [00:51<00:00,  4.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusting learning rate of group 0 to 1.6220e-05.\n",
      "NN data gathering time: 89.54605317115784\n",
      "json loading time:  4.3928704261779785\n",
      "{'tr_prev_probs': 2.2126007080078125, 'graph_features': 0.0008566379547119141, 'tr_features': 0.016707420349121094, 'tr_graph_ids': 0.001169443130493164, 'tr_queues': 3.1738641262054443, 'cat graph features': 5.9604644775390625e-06, 'graphs_data': 1.0728836059570312e-05}\n",
      "j2torch time:  7.278268337249756\n",
      "{'traj_length mean, median, max': ('171.71', 24.0, 1501), 'queue max length, idx': (58, 38418), 'number of train states': 47560, 'number of traj-s': 378, 'number of validation traj-s': 86}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 250/250 [00:55<00:00,  4.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusting learning rate of group 0 to 1.6040e-05.\n",
      "NN data gathering time: 98.24895095825195\n",
      "json loading time:  3.883312940597534\n",
      "{'tr_prev_probs': 1.7720491886138916, 'graph_features': 0.0008058547973632812, 'tr_features': 0.017233848571777344, 'tr_graph_ids': 0.0012660026550292969, 'tr_queues': 2.5211069583892822, 'cat graph features': 2.4557113647460938e-05, 'graphs_data': 7.152557373046875e-06}\n",
      "j2torch time:  6.113448858261108\n",
      "{'traj_length mean, median, max': ('184.88', 29.0, 1501), 'queue max length, idx': (53, 6364), 'number of train states': 56473, 'number of traj-s': 373, 'number of validation traj-s': 78}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 250/250 [00:39<00:00,  6.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusting learning rate of group 0 to 1.5860e-05.\n",
      "NN data gathering time: 104.43959712982178\n",
      "json loading time:  4.5773162841796875\n",
      "{'tr_prev_probs': 1.6445131301879883, 'graph_features': 0.0006575584411621094, 'tr_features': 0.01661229133605957, 'tr_graph_ids': 0.0012598037719726562, 'tr_queues': 2.5658953189849854, 'cat graph features': 6.198883056640625e-06, 'graphs_data': 4.291534423828125e-06}\n",
      "j2torch time:  5.858936071395874\n",
      "{'traj_length mean, median, max': ('183.33', 24.0, 1501), 'queue max length, idx': (74, 38635), 'number of train states': 52297, 'number of traj-s': 373, 'number of validation traj-s': 84}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 250/250 [00:43<00:00,  5.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusting learning rate of group 0 to 1.5680e-05.\n",
      "NN data gathering time: 91.84328484535217\n",
      "json loading time:  2.819647789001465\n",
      "{'tr_prev_probs': 1.6012725830078125, 'graph_features': 0.0007703304290771484, 'tr_features': 0.015758991241455078, 'tr_graph_ids': 0.0012736320495605469, 'tr_queues': 2.233349561691284, 'cat graph features': 6.9141387939453125e-06, 'graphs_data': 5.4836273193359375e-06}\n",
      "j2torch time:  5.496665954589844\n",
      "{'traj_length mean, median, max': ('167.41', 28.0, 1401), 'queue max length, idx': (49, 41206), 'number of train states': 51312, 'number of traj-s': 381, 'number of validation traj-s': 78}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 250/250 [00:40<00:00,  6.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusting learning rate of group 0 to 1.5500e-05.\n",
      "NN data gathering time: 93.66808795928955\n",
      "json loading time:  3.025022029876709\n",
      "{'tr_prev_probs': 1.536731481552124, 'graph_features': 0.0009644031524658203, 'tr_features': 0.015108823776245117, 'tr_graph_ids': 0.0011973381042480469, 'tr_queues': 1.7327001094818115, 'cat graph features': 6.198883056640625e-06, 'graphs_data': 9.059906005859375e-06}\n",
      "j2torch time:  4.877683877944946\n",
      "{'traj_length mean, median, max': ('159.18', 34.0, 1501), 'queue max length, idx': (38, 19580), 'number of train states': 47535, 'number of traj-s': 389, 'number of validation traj-s': 91}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 250/250 [00:39<00:00,  6.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusting learning rate of group 0 to 1.5320e-05.\n",
      "NN data gathering time: 89.05420637130737\n",
      "json loading time:  5.146982431411743\n",
      "{'tr_prev_probs': 1.8979394435882568, 'graph_features': 0.0007734298706054688, 'tr_features': 0.018247365951538086, 'tr_graph_ids': 0.0013849735260009766, 'tr_queues': 2.2173848152160645, 'cat graph features': 6.198883056640625e-06, 'graphs_data': 5.245208740234375e-06}\n",
      "j2torch time:  6.014786005020142\n",
      "{'traj_length mean, median, max': ('198.54', 29.0, 1501), 'queue max length, idx': (67, 42981), 'number of train states': 59561, 'number of traj-s': 381, 'number of validation traj-s': 90}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 250/250 [00:40<00:00,  6.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusting learning rate of group 0 to 1.5140e-05.\n",
      "NN data gathering time: 98.63908648490906\n",
      "json loading time:  3.9301228523254395\n",
      "{'tr_prev_probs': 1.5191614627838135, 'graph_features': 0.0006275177001953125, 'tr_features': 0.01449894905090332, 'tr_graph_ids': 0.001089334487915039, 'tr_queues': 2.221466064453125, 'cat graph features': 4.76837158203125e-06, 'graphs_data': 4.76837158203125e-06}\n",
      "j2torch time:  5.269061803817749\n",
      "{'traj_length mean, median, max': ('164.46', 28.5, 1501), 'queue max length, idx': (50, 8293), 'number of train states': 49203, 'number of traj-s': 398, 'number of validation traj-s': 87}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 250/250 [00:38<00:00,  6.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusting learning rate of group 0 to 1.4960e-05.\n",
      "NN data gathering time: 100.04251098632812\n",
      "json loading time:  4.108374118804932\n",
      "{'tr_prev_probs': 1.4839041233062744, 'graph_features': 0.0006630420684814453, 'tr_features': 0.01447153091430664, 'tr_graph_ids': 0.0011529922485351562, 'tr_queues': 1.7469539642333984, 'cat graph features': 5.0067901611328125e-06, 'graphs_data': 8.344650268554688e-06}\n",
      "j2torch time:  4.735868692398071\n",
      "{'traj_length mean, median, max': ('144.15', 26.0, 1501), 'queue max length, idx': (71, 32767), 'number of train states': 47281, 'number of traj-s': 384, 'number of validation traj-s': 78}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 250/250 [00:41<00:00,  5.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusting learning rate of group 0 to 1.4780e-05.\n",
      "NN data gathering time: 95.26145362854004\n",
      "json loading time:  3.6900806427001953\n",
      "{'tr_prev_probs': 1.5481030941009521, 'graph_features': 0.0006935596466064453, 'tr_features': 0.014743566513061523, 'tr_graph_ids': 0.0012111663818359375, 'tr_queues': 1.780893087387085, 'cat graph features': 5.7220458984375e-06, 'graphs_data': 5.0067901611328125e-06}\n",
      "j2torch time:  4.916708707809448\n",
      "{'traj_length mean, median, max': ('179.53', 28.0, 1501), 'queue max length, idx': (51, 1625), 'number of train states': 49612, 'number of traj-s': 386, 'number of validation traj-s': 82}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 250/250 [00:36<00:00,  6.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusting learning rate of group 0 to 1.4600e-05.\n",
      "NN data gathering time: 86.17546224594116\n",
      "json loading time:  3.407054901123047\n",
      "{'tr_prev_probs': 1.7525634765625, 'graph_features': 0.0007398128509521484, 'tr_features': 0.01697850227355957, 'tr_graph_ids': 0.0013592243194580078, 'tr_queues': 2.459259033203125, 'cat graph features': 1.2874603271484375e-05, 'graphs_data': 8.106231689453125e-06}\n",
      "j2torch time:  5.972339153289795\n",
      "{'traj_length mean, median, max': ('169.34', 29.5, 1501), 'queue max length, idx': (42, 24722), 'number of train states': 56308, 'number of traj-s': 400, 'number of validation traj-s': 80}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 250/250 [00:35<00:00,  7.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusting learning rate of group 0 to 1.4420e-05.\n",
      "NN data gathering time: 84.78720426559448\n",
      "json loading time:  3.7100272178649902\n",
      "{'tr_prev_probs': 1.7542977333068848, 'graph_features': 0.0010235309600830078, 'tr_features': 0.016382455825805664, 'tr_graph_ids': 0.0012412071228027344, 'tr_queues': 2.02129864692688, 'cat graph features': 8.344650268554688e-06, 'graphs_data': 1.1682510375976562e-05}\n",
      "j2torch time:  5.549696445465088\n",
      "{'traj_length mean, median, max': ('175.68', 29.5, 1501), 'queue max length, idx': (65, 40052), 'number of train states': 55205, 'number of traj-s': 394, 'number of validation traj-s': 82}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 250/250 [00:40<00:00,  6.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusting learning rate of group 0 to 1.4240e-05.\n",
      "NN data gathering time: 90.91972875595093\n",
      "json loading time:  3.9110844135284424\n",
      "{'tr_prev_probs': 1.6831626892089844, 'graph_features': 0.0006420612335205078, 'tr_features': 0.015718698501586914, 'tr_graph_ids': 0.0012555122375488281, 'tr_queues': 1.9239435195922852, 'cat graph features': 6.198883056640625e-06, 'graphs_data': 5.245208740234375e-06}\n",
      "j2torch time:  5.867390871047974\n",
      "{'traj_length mean, median, max': ('181.31', 27.0, 1348), 'queue max length, idx': (44, 44196), 'number of train states': 53895, 'number of traj-s': 393, 'number of validation traj-s': 88}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 250/250 [00:37<00:00,  6.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusting learning rate of group 0 to 1.4060e-05.\n",
      "NN data gathering time: 96.38421869277954\n",
      "json loading time:  3.4093616008758545\n",
      "{'tr_prev_probs': 1.5733697414398193, 'graph_features': 0.0006222724914550781, 'tr_features': 0.014539957046508789, 'tr_graph_ids': 0.0011663436889648438, 'tr_queues': 1.7721717357635498, 'cat graph features': 5.245208740234375e-06, 'graphs_data': 5.245208740234375e-06}\n",
      "j2torch time:  5.018129825592041\n",
      "{'traj_length mean, median, max': ('169.60', 25.0, 1501), 'queue max length, idx': (46, 33960), 'number of train states': 51678, 'number of traj-s': 382, 'number of validation traj-s': 82}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 250/250 [00:36<00:00,  6.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusting learning rate of group 0 to 1.3880e-05.\n",
      "NN data gathering time: 77.2356345653534\n",
      "json loading time:  2.505060911178589\n",
      "{'tr_prev_probs': 1.3271539211273193, 'graph_features': 0.0007164478302001953, 'tr_features': 0.013369083404541016, 'tr_graph_ids': 0.0011088848114013672, 'tr_queues': 1.4753475189208984, 'cat graph features': 4.76837158203125e-06, 'graphs_data': 5.7220458984375e-06}\n",
      "j2torch time:  4.244013786315918\n",
      "{'traj_length mean, median, max': ('128.15', 27.0, 1501), 'queue max length, idx': (27, 38808), 'number of train states': 41411, 'number of traj-s': 404, 'number of validation traj-s': 79}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 250/250 [00:35<00:00,  7.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusting learning rate of group 0 to 1.3700e-05.\n",
      "NN data gathering time: 91.68827652931213\n",
      "json loading time:  3.325035810470581\n",
      "{'tr_prev_probs': 2.2456579208374023, 'graph_features': 0.0008215904235839844, 'tr_features': 0.01660323143005371, 'tr_graph_ids': 0.0012972354888916016, 'tr_queues': 2.00858211517334, 'cat graph features': 5.9604644775390625e-06, 'graphs_data': 8.344650268554688e-06}\n",
      "j2torch time:  6.039960861206055\n",
      "{'traj_length mean, median, max': ('184.56', 30.0, 1459), 'queue max length, idx': (53, 36361), 'number of train states': 52811, 'number of traj-s': 383, 'number of validation traj-s': 89}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 250/250 [00:38<00:00,  6.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusting learning rate of group 0 to 1.3520e-05.\n",
      "NN data gathering time: 61.40294647216797\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Pretrain\n",
    "\n",
    "epochs = 100\n",
    "train_condition, message = (lambda tr: tr[0]%5 != 2), '%5!=2'\n",
    "checkpoint_path = '../Checkpoints/actor(Double), critic'\n",
    "checkpoint_actor = torch.load(checkpoint_path)['actor']\n",
    "checkpoint_critic = torch.load(checkpoint_path)['critic']\n",
    "\n",
    "actor = copy.deepcopy(checkpoint_actor).to(device).train()\n",
    "actor_opt = torch.optim.AdamW(actor.parameters(), lr=2e-5, weight_decay=2e-3,)\n",
    "actor_sched = torch.optim.lr_scheduler.LinearLR(actor_opt, start_factor=1, end_factor=0.1, total_iters=epochs, verbose=True)\n",
    "critic = copy.deepcopy(checkpoint_critic).to(device).train()\n",
    "critic_opt = torch.optim.AdamW(critic.parameters(), lr=2e-5, weight_decay=0.05)\n",
    "gnn, gnn_opt = get_gnn_setup(gnn_in_nfeatures, gnn_out_nfeatures)\n",
    "\n",
    "trajectories = Trajectories(train_condition=train_condition,\n",
    "                                use_gnn=use_gnn,\n",
    "                                gnn_out_nfeatures=gnn_out_nfeatures,\n",
    "                                gnn_in_nfeatures=gnn_in_nfeatures)    \n",
    "run = wandb.init(\n",
    "      project=\"PS\",\n",
    "      name=f'tune double no_gnn',\n",
    "      config={\n",
    "          'algorithm': 'PPO-clip',\n",
    "          'models': 'mlp + attn',\n",
    "      }\n",
    ")\n",
    "\n",
    "with open('../Game_env/jar_config.txt', 'w') as jar_config:\n",
    "  jar_config.write(json.dumps({'postprocessing': 'None', \n",
    "                               'dataConsumption': 100,\n",
    "                               'maxAttentionLength': max_nactions,\n",
    "                               'inputShape': [1, -1, features_dim],\n",
    "                               'defaultAlgorithm': 'BFS',\n",
    "                               \"maxConcurrency\": 64,\n",
    "                               'useGnn': use_gnn}))  \n",
    "trajectories.gather_n_store(actor_model=checkpoint_actor, gnn_model=gnn)\n",
    "trajectories.evaluate_val_train()\n",
    "print(trajectories.get_properties())\n",
    "\n",
    "# actor, actor_opt, actor_sched = get_attn_setup(epochs=epochs, use_double=True)\n",
    "# critic, critic_opt = get_mlp_setup(use_FFM=True)\n",
    "\n",
    "for epoch in range(epochs):  \n",
    "    with open('../Game_env/jar_config.txt', 'w') as jar_config:\n",
    "      jar_config.write(json.dumps({'postprocessing': 'None', \n",
    "                                   'dataConsumption': consumption_percent(epoch),\n",
    "                                   'maxAttentionLength': max_nactions,\n",
    "                                   'inputShape': [1, -1, features_dim],\n",
    "                                   'defaultAlgorithm': 'BFS',\n",
    "                                   \"maxConcurrency\": 64,\n",
    "                                   'useGnn': use_gnn}))  \n",
    "\n",
    "    trainer = NN_Trainer(NN_setup={'gnn': gnn, 'gnn_opt': gnn_opt,\n",
    "                                   'actor': actor, 'actor_opt': actor_opt, 'actor_sched': actor_sched,\n",
    "                                   'critic': critic, 'critic_opt': critic_opt,},\n",
    "                         trajectories=trajectories,\n",
    "                         n_batches=250,\n",
    "                         clip_eps = get_clip_eps(epoch),\n",
    "                         use_gnn=use_gnn,\n",
    "                         gnn_out_nfeatures=gnn_out_nfeatures,\n",
    "                         )\n",
    "    trainer.learn_new_policy()\n",
    "    wandb.log({'epoch': epoch})\n",
    "    trajectories.gather_n_store(actor_model=actor, gnn_model=gnn)\n",
    "    trajectories.evaluate_val_train()\n",
    "    print(trajectories.get_properties())\n",
    "\n",
    "checkpoint = {\n",
    "  'actor': actor,\n",
    "  'critic':critic,\n",
    "}\n",
    "torch.save(checkpoint, os.path.join(wandb.run.dir, f'actor, critic'))\n",
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # No pretrain\n",
    "\n",
    "# epochs = 150\n",
    "# train_condition, message = (lambda tr: tr[0]%5 != 2), '%5!=2'\n",
    "\n",
    "# for _ in [0]:\n",
    "#     trajectories = Trajectories(train_condition=train_condition,\n",
    "#                                 use_gnn=use_gnn,\n",
    "#                                 gnn_out_nfeatures=gnn_out_nfeatures,\n",
    "#                                 gnn_in_nfeatures=gnn_in_nfeatures)\n",
    "#     run = wandb.init(\n",
    "#           project=\"PS\",\n",
    "#           name=f'double_att, no_gnn, val {message}',\n",
    "#           config={\n",
    "#               'algorithm': 'PPO-clip',\n",
    "#               'models': 'mlp + attn',\n",
    "#           }\n",
    "#     )\n",
    "#     with open('../Game_env/jar_config.txt', 'w') as jar_config:\n",
    "#       jar_config.write(json.dumps({'postprocessing': 'None', \n",
    "#                                    'dataConsumption': 100,\n",
    "#                                    'maxAttentionLength': max_nactions,\n",
    "#                                    'inputShape': [1, -1, features_dim],\n",
    "#                                    'defaultAlgorithm': 'BFS',\n",
    "#                                    \"maxConcurrency\": 120,\n",
    "#                                    'useGnn': use_gnn}))    \n",
    "#     trajectories.gather_n_store()\n",
    "#     trajectories.evaluate_val_train()\n",
    "#     print(trajectories.get_properties())\n",
    "\n",
    "#     gnn, gnn_opt = get_gnn_setup(gnn_in_nfeatures, gnn_out_nfeatures)\n",
    "#     actor, actor_opt, actor_sched = get_attn_setup(epochs=epochs, use_double=False)\n",
    "#     critic, critic_opt = get_mlp_setup(use_FFM=True)\n",
    "\n",
    "#     with open('../Game_env/jar_config.txt', 'w') as jar_config:\n",
    "#       jar_config.write(json.dumps({'postprocessing': 'None', \n",
    "#                                    'dataConsumption': consumption_percent(0), # consumption_percent(0),\n",
    "#                                    'maxAttentionLength': max_nactions,\n",
    "#                                    'inputShape': [1, -1, features_dim],\n",
    "#                                    \"maxConcurrency\": 120,\n",
    "#                                    'useGnn': use_gnn}))\n",
    "#     trajectories.gather_n_store(actor_model=actor, gnn_model=gnn)\n",
    "#     trajectories.evaluate_val_train()\n",
    "#     print(trajectories.get_properties())\n",
    "\n",
    "#     for epoch in range(epochs):  \n",
    "#         with open('../Game_env/jar_config.txt', 'w') as jar_config:\n",
    "#           jar_config.write(json.dumps({'postprocessing': 'None', \n",
    "#                                        'dataConsumption': consumption_percent(epoch),\n",
    "#                                        'maxAttentionLength': max_nactions,\n",
    "#                                        \"maxConcurrency\": 120,\n",
    "#                                        'inputShape': [1, -1, len(trajectories.feature_names) + (gnn_out_nfeatures if use_gnn else 0)],\n",
    "#                                        'useGnn': use_gnn}))\n",
    "\n",
    "#         trainer = NN_Trainer(NN_setup={'gnn': gnn, 'gnn_opt': gnn_opt,\n",
    "#                                        'actor': actor, 'actor_opt': actor_opt, 'actor_sched': actor_sched,\n",
    "#                                        'critic': critic, 'critic_opt': critic_opt,},\n",
    "#                              trajectories=trajectories,\n",
    "#                              n_batches=800,\n",
    "#                              clip_eps = get_clip_eps(epoch),\n",
    "#                              use_gnn=use_gnn,\n",
    "#                              gnn_out_nfeatures=gnn_out_nfeatures,\n",
    "#                              )\n",
    "#         trainer.learn_new_policy()\n",
    "#         wandb.log({'epoch': epoch,})\n",
    "#         trajectories.gather_n_store(actor_model=actor, gnn_model=gnn)\n",
    "#         trajectories.evaluate_val_train()\n",
    "#         print(trajectories.get_properties())\n",
    "\n",
    "#     checkpoint = {\n",
    "#       # 'gnn': gnn,\n",
    "#       'actor': actor,\n",
    "#       'critic':critic,\n",
    "#     }\n",
    "#     torch.save(checkpoint, os.path.join(wandb.run.dir, f'actor, critic'))\n",
    "#     wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # Learn V\n",
    "\n",
    "# train_condition, message = (lambda tr: 'com.' in tr[2]), 'com.'\n",
    "# epochs=1\n",
    "\n",
    "# trajectories = Trajectories(train_condition=train_condition,\n",
    "#                             use_gnn=use_gnn,\n",
    "#                             gnn_out_nfeatures=gnn_out_nfeatures,\n",
    "#                             gnn_in_nfeatures=gnn_in_nfeatures)    \n",
    "# # run = wandb.init(\n",
    "# #       project=\"delete 3\",\n",
    "# #       name=f'Critic play, val {message}',\n",
    "# #       config={\n",
    "# #           'algorithm': 'PPO-clip',\n",
    "# #           'models': 'mlp + attn',\n",
    "# #       }\n",
    "# # )\n",
    "\n",
    "# actor, actor_opt, actor_sched = get_attn_setup(epochs=epochs, use_double=False)\n",
    "# critic, critic_opt = get_mlp_setup(use_FFM=True)\n",
    "# gnn, gnn_opt = get_gnn_setup(gnn_in_nfeatures, gnn_out_nfeatures)\n",
    "\n",
    "# with open('../Game_env/jar_config.txt', 'w') as jar_config:\n",
    "#   jar_config.write(json.dumps({'postprocessing': 'None', \n",
    "#                                'dataConsumption': consumption_percent(100),\n",
    "#                                'maxAttentionLength': max_nactions,\n",
    "#                                'inputShape': [1, -1, features_dim],\n",
    "#                                'useGnn': use_gnn}))\n",
    "\n",
    "# # trajectories.gather_n_store(actor_model=actor, gnn_model=gnn)\n",
    "# trajectories.store_from_json()\n",
    "# trajectories.evaluate_val_train()\n",
    "# print(trajectories.get_properties())\n",
    "\n",
    "# trainer = NN_Trainer(NN_setup={'gnn': gnn, 'gnn_opt': gnn_opt,\n",
    "#                                    'actor': actor, 'actor_opt': actor_opt, 'actor_sched': actor_sched,\n",
    "#                                    'critic': critic, 'critic_opt': critic_opt,},\n",
    "#                          trajectories=trajectories,\n",
    "#                          n_batches=int(2500 * consumption_percent(100)/100),\n",
    "#                          clip_eps = get_clip_eps(100),\n",
    "#                          use_gnn=use_gnn,\n",
    "#                          gnn_out_nfeatures=gnn_out_nfeatures,\n",
    "#                          )\n",
    "# trainer.learn_v(5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # Critic Play\n",
    "\n",
    "# epochs = 50\n",
    "# train_condition, message = (lambda tr: 'com.' in tr[2]), 'com.'\n",
    "\n",
    "# for _ in [0]:\n",
    "#     trajectories = Trajectories(train_condition=train_condition,\n",
    "#                                 use_gnn=use_gnn,\n",
    "#                                 gnn_out_nfeatures=gnn_out_nfeatures,\n",
    "#                                 gnn_in_nfeatures=gnn_in_nfeatures)    \n",
    "#     run = wandb.init(\n",
    "#           project=\"delete 3\",\n",
    "#           name=f'Critic play, val {message}',\n",
    "#           config={\n",
    "#               'algorithm': 'PPO-clip',\n",
    "#               'models': 'mlp + attn',\n",
    "#           }\n",
    "#     )\n",
    "    \n",
    "#     with open('../Game_env/jar_config.txt', 'w') as jar_config:\n",
    "#       jar_config.write(json.dumps({'postprocessing': 'None', \n",
    "#                                    'dataConsumption': consumption_percent(100),\n",
    "#                                    'maxAttentionLength': -1,\n",
    "#                                    'inputShape': [-1, features_dim],\n",
    "#                                    'defaultAlgorithm': 'ForkDepthRandom',\n",
    "#                                    'useGnn': use_gnn}))\n",
    "#     trajectories.gather_n_store()\n",
    "#     # trajectories.store_from_json()\n",
    "#     trajectories.evaluate_val_train()\n",
    "#     print(trajectories.get_properties())\n",
    "\n",
    "#     actor, actor_opt, actor_sched = get_attn_setup(epochs=epochs, use_double=False)\n",
    "#     critic, critic_opt = get_mlp_setup(use_FFM=True)\n",
    "#     q_net = Q_Net(V_function=critic, reward_ind=trajectories.j_file['scheme'][0].index('logReward'))\n",
    "#     gnn, gnn_opt = get_gnn_setup(gnn_in_nfeatures, gnn_out_nfeatures)\n",
    "    \n",
    "#     with open('../Game_env/jar_config.txt', 'w') as jar_config:\n",
    "#       jar_config.write(json.dumps({'postprocessing': 'None', \n",
    "#                                    'dataConsumption': consumption_percent(100),\n",
    "#                                    'maxAttentionLength': max_nactions,\n",
    "#                                    'inputShape': [1, -1, features_dim],\n",
    "#                                    'useGnn': use_gnn}))\n",
    "    \n",
    "#     trajectories.gather_n_store(actor_model=actor, gnn_model=gnn)\n",
    "#     trajectories.evaluate_val_train()\n",
    "#     print(trajectories.get_properties())\n",
    "\n",
    "#     for epoch in range(epochs):  \n",
    "#         with open('../Game_env/jar_config.txt', 'w') as jar_config:\n",
    "#           jar_config.write(json.dumps({'postprocessing': 'Argmax', \n",
    "#                                        'dataConsumption': consumption_percent(epoch),\n",
    "#                                        'maxAttentionLength': max_nactions,\n",
    "#                                        'inputShape': [-1, features_dim],\n",
    "#                                        'useGnn': use_gnn}))\n",
    "        \n",
    "#         trainer = NN_Trainer(NN_setup={'gnn': gnn, 'gnn_opt': gnn_opt,\n",
    "#                                        'actor': actor, 'actor_opt': actor_opt, 'actor_sched': actor_sched,\n",
    "#                                        'critic': critic, 'critic_opt': critic_opt,},\n",
    "#                              trajectories=trajectories,\n",
    "#                              n_batches=int(2500 * consumption_percent(epoch)/100),\n",
    "#                              clip_eps = get_clip_eps(epoch),\n",
    "#                              use_gnn=use_gnn,\n",
    "#                              gnn_out_nfeatures=gnn_out_nfeatures,\n",
    "#                              )\n",
    "#         trainer.learn_new_policy()\n",
    "#         wandb.log({'epoch': epoch})\n",
    "#         trajectories.gather_n_store(actor_model=q_net, gnn_model=gnn)\n",
    "#         trajectories.evaluate_val_train()\n",
    "#         print(trajectories.get_properties())\n",
    "\n",
    "#     checkpoint = {\n",
    "#       'gnn': gnn,\n",
    "#       'actor': actor,\n",
    "#       'critic':critic,\n",
    "#     }\n",
    "#     # torch.save(checkpoint, os.path.join(wandb.run.dir, f'actor, critic'))\n",
    "#     wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "google.colab.output.setIframeHeight(0, true, {maxHeight: 600})"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<IPython.core.display.HTML object>\n",
      "VBox(children=(Label(value='0.014 MB of 0.014 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max=1.0)))\n",
      "<IPython.core.display.HTML object>\n",
      "<IPython.core.display.HTML object>\n",
      "<IPython.core.display.HTML object>\n"
     ]
    }
   ],
   "source": [
    "exit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Data filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_condition, message = (lambda tr: True), 'wtf'\n",
    "# with open('../Game_env/jar_config.txt', 'w') as jar_config:\n",
    "#       jar_config.write(json.dumps({'postprocessing': 'None', \n",
    "#                                    'dataConsumption': 100,\n",
    "#                                    'maxAttentionLength': max_nactions,\n",
    "#                                    'inputShape': [1, -1, features_dim],\n",
    "#                                    'useGnn': use_gnn}))\n",
    "# trajectories = Trajectories(train_condition=train_condition,\n",
    "#                                 use_gnn=use_gnn,\n",
    "#                                 gnn_out_nfeatures=gnn_out_nfeatures,\n",
    "#                                 gnn_in_nfeatures=gnn_in_nfeatures)\n",
    "# trajectories.store_from_json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # open('../Game_env/blacklist.txt', 'w').close()\n",
    "\n",
    "# print(trajectories.get_properties())\n",
    "# paths = trajectories.j_file['paths']\n",
    "\n",
    "# import matplotlib.pyplot as plt\n",
    "# lengths = [len(paths[i][1]) for i in range(len(paths))]\n",
    "# lengths_t = torch.Tensor(lengths)\n",
    "# print([lengths_t.quantile(10*i/100) for i in range(10)])\n",
    "# # plt.hist([l for l in lengths if (l>0 and l<1502)], bins=500)\n",
    "# # plt.show()\n",
    "\n",
    "# max_queue_len = [max([len(q[0]) for q in paths[i][1]]) for i in range(len(paths))]\n",
    "# max_queue_len_t = torch.Tensor(max_queue_len)\n",
    "# print([max_queue_len_t.quantile(10*i/100) for i in range(11)])\n",
    "# mean_queue_len = [torch.Tensor([len(q[0]) for q in paths[i][1]]).mean() for i in range(len(paths))]\n",
    "# mean_queue_len_t = torch.Tensor(mean_queue_len)\n",
    "# print([mean_queue_len_t.quantile(10*i/100) for i in range(11)])\n",
    "\n",
    "# print(lengths_t[torch.nonzero(mean_queue_len_t<=1.1).squeeze()].sum())\n",
    "\n",
    "# ids = torch.nonzero((mean_queue_len_t<=1.1)).long().squeeze()\n",
    "# print(len(ids))\n",
    "# bad_paths = [paths[i] for i in ids]\n",
    "# [bad_paths[i][2] for i in range(len(bad_paths))][:10]\n",
    "\n",
    "# with open('../Game_env/blacklist.txt', 'a') as f:\n",
    "#   for i in range(len(ids)):\n",
    "#     s = bad_paths[i][2]\n",
    "#     f.write(s + '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The end"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "VTYQZ1qL9gFa",
    "tRSEdgzW9gFc",
    "mRN1NVVF9gFf"
   ],
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python [conda env:.conda-envatt] *",
   "language": "python",
   "name": "conda-env-.conda-envatt-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
